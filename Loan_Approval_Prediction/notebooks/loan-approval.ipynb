{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-29T15:14:25.859639Z",
     "iopub.status.busy": "2024-10-29T15:14:25.859146Z",
     "iopub.status.idle": "2024-10-29T15:14:26.346147Z",
     "shell.execute_reply": "2024-10-29T15:14:26.344852Z",
     "shell.execute_reply.started": "2024-10-29T15:14:25.859574Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T15:14:56.676757Z",
     "iopub.status.busy": "2024-10-29T15:14:56.676265Z",
     "iopub.status.idle": "2024-10-29T15:14:57.675372Z",
     "shell.execute_reply": "2024-10-29T15:14:57.673975Z",
     "shell.execute_reply.started": "2024-10-29T15:14:56.676705Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# kaggle datasets download chilledwanker/loan-approval-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "with ZipFile('loan-approval-prediction.zip', 'r') as zipObj:\n",
    "   # Extract all the contents of zip file in current directory\n",
    "   zipObj.extractall('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the base path and the relative path\n",
    "base_path = r\"C:\\Users\\HP\\Documents\\Kaggle Projects\\Loan Approval Prediction\\data\"\n",
    "train_file_name = \"playground-series-s4e10/train.csv\"\n",
    "test_file_name = \"playground-series-s4e10/test.csv\"\n",
    "sub_file_name = \"playground-series-s4e10/sample_submission.csv\"\n",
    "# Join paths\n",
    "train_file_path = os.path.join(base_path, train_file_name)\n",
    "test_file_path = os.path.join(base_path, test_file_name)\n",
    "sub_file_path = os.path.join(base_path, sub_file_name)\n",
    "orig_file_path = os.path.join(base_path, \"credit_risk_dataset.csv\")\n",
    "# Load CSV\n",
    "train_df = pd.read_csv(train_file_path)\n",
    "test_df = pd.read_csv(test_file_path)\n",
    "sub_df = pd.read_csv(sub_file_path)\n",
    "\n",
    "original_df = pd.read_csv(orig_file_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T15:14:57.679424Z",
     "iopub.status.busy": "2024-10-29T15:14:57.678893Z",
     "iopub.status.idle": "2024-10-29T15:14:58.138935Z",
     "shell.execute_reply": "2024-10-29T15:14:58.137639Z",
     "shell.execute_reply.started": "2024-10-29T15:14:57.679363Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# train_df = pd.read_csv('/kaggle/input/playground-series-s4e10/train.csv')\n",
    "# test_df = pd.read_csv('/kaggle/input/playground-series-s4e10/test.csv')\n",
    "# sub_df = pd.read_csv('/kaggle/input/playground-series-s4e10/sample_submission.csv')\n",
    "# original_df = pd.read_csv('/kaggle/input/loan-approval-prediction/credit_risk_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T15:14:58.140675Z",
     "iopub.status.busy": "2024-10-29T15:14:58.140290Z",
     "iopub.status.idle": "2024-10-29T15:14:58.177893Z",
     "shell.execute_reply": "2024-10-29T15:14:58.176352Z",
     "shell.execute_reply.started": "2024-10-29T15:14:58.140634Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df.drop(columns=\"id\")\n",
    "train_df = pd.concat([train_df, original_df], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T15:14:58.179923Z",
     "iopub.status.busy": "2024-10-29T15:14:58.179516Z",
     "iopub.status.idle": "2024-10-29T15:14:58.218274Z",
     "shell.execute_reply": "2024-10-29T15:14:58.216955Z",
     "shell.execute_reply.started": "2024-10-29T15:14:58.179879Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['person_home_ownership',\n",
       "  'loan_intent',\n",
       "  'loan_grade',\n",
       "  'cb_person_default_on_file'],\n",
       " ['person_age',\n",
       "  'person_income',\n",
       "  'person_emp_length',\n",
       "  'loan_amnt',\n",
       "  'loan_int_rate',\n",
       "  'loan_percent_income',\n",
       "  'cb_person_cred_hist_length'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols = [col for col in train_df.select_dtypes(exclude=['int', 'float']).columns if col not in ('id', 'loan_status')]\n",
    "num_cols = [col for col in train_df.select_dtypes(include=['int', 'float']).columns if col not in ('id', 'loan_status')]\n",
    "\n",
    "cat_cols, num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T15:14:58.220447Z",
     "iopub.status.busy": "2024-10-29T15:14:58.220043Z",
     "iopub.status.idle": "2024-10-29T15:14:58.276917Z",
     "shell.execute_reply": "2024-10-29T15:14:58.275525Z",
     "shell.execute_reply.started": "2024-10-29T15:14:58.220405Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "person_age                       0\n",
       "person_income                    0\n",
       "person_home_ownership            0\n",
       "person_emp_length              895\n",
       "loan_intent                      0\n",
       "loan_grade                       0\n",
       "loan_amnt                        0\n",
       "loan_int_rate                 3116\n",
       "loan_percent_income              0\n",
       "cb_person_default_on_file        0\n",
       "cb_person_cred_hist_length       0\n",
       "loan_status                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T15:14:58.279161Z",
     "iopub.status.busy": "2024-10-29T15:14:58.278619Z",
     "iopub.status.idle": "2024-10-29T15:14:58.332662Z",
     "shell.execute_reply": "2024-10-29T15:14:58.331192Z",
     "shell.execute_reply.started": "2024-10-29T15:14:58.279102Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# na_df = train_df.isna().sum()\n",
    "# na_cols  = [col for col in na_df.index if na_df[col] > 0]\n",
    "# na_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T15:17:09.339346Z",
     "iopub.status.busy": "2024-10-29T15:17:09.338578Z",
     "iopub.status.idle": "2024-10-29T15:17:09.906836Z",
     "shell.execute_reply": "2024-10-29T15:17:09.905376Z",
     "shell.execute_reply.started": "2024-10-29T15:17:09.339298Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imputing using Ridge()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "import copy\n",
    "\n",
    "ridge = Ridge(alpha=1.0)\n",
    "lasso = Lasso(alpha=1.0)\n",
    "\n",
    "imputed_dfs = {}\n",
    "for model in [ridge, lasso]:\n",
    "    df = copy.deepcopy(train_df)\n",
    "    df = df[num_cols]\n",
    "    print(f'imputing using {model}')\n",
    "    imputer = IterativeImputer(estimator=model, max_iter=1500, random_state=0, tol=1e-1)\n",
    "    imputed_df = pd.DataFrame(imputer.fit_transform(df), columns=df.columns, index=df.index )\n",
    "    model_name = model.__class__.__name__\n",
    "    imputed_dfs[model_name] = imputed_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T15:17:14.062584Z",
     "iopub.status.busy": "2024-10-29T15:17:14.062139Z",
     "iopub.status.idle": "2024-10-29T15:17:14.119647Z",
     "shell.execute_reply": "2024-10-29T15:17:14.118331Z",
     "shell.execute_reply.started": "2024-10-29T15:17:14.062542Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ridge_imputed_df = imputed_dfs['Ridge']\n",
    "train_df[num_cols] = ridge_imputed_df[num_cols]\n",
    "train_df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T15:42:00.846634Z",
     "iopub.status.busy": "2024-10-29T15:42:00.845765Z",
     "iopub.status.idle": "2024-10-29T15:42:00.855804Z",
     "shell.execute_reply": "2024-10-29T15:42:00.854667Z",
     "shell.execute_reply.started": "2024-10-29T15:42:00.846581Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df['income_to_loan_ratio'] = train_df['person_income'] / train_df['loan_amnt']\n",
    "train_df['age_emp_length']  = train_df['person_age'] * train_df['person_emp_length']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T15:43:59.153313Z",
     "iopub.status.busy": "2024-10-29T15:43:59.152798Z",
     "iopub.status.idle": "2024-10-29T15:43:59.180623Z",
     "shell.execute_reply": "2024-10-29T15:43:59.179415Z",
     "shell.execute_reply.started": "2024-10-29T15:43:59.153267Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cat_cols = [col for col in train_df.select_dtypes(exclude=['int', 'float']).columns if col not in ('id', 'loan_status')]\n",
    "num_cols = [col for col in train_df.select_dtypes(include=['int', 'float']).columns if col not in ('id', 'loan_status')]\n",
    "\n",
    "cat_cols, num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T15:45:43.064179Z",
     "iopub.status.busy": "2024-10-29T15:45:43.063691Z",
     "iopub.status.idle": "2024-10-29T15:45:45.714589Z",
     "shell.execute_reply": "2024-10-29T15:45:45.713316Z",
     "shell.execute_reply.started": "2024-10-29T15:45:43.064129Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import copy \n",
    "def box_plots_num_cols(df:pd.DataFrame, num_columns:list[str]):\n",
    "    df = copy.deepcopy(df)\n",
    "    base_width = 5\n",
    "    base_height = 3\n",
    "    columns = num_columns\n",
    "    cols = round(len(columns) / 2)\n",
    "    rows = len(columns) - cols\n",
    "    fig_width = cols * base_width\n",
    "    fig_height = rows * base_height\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(fig_width, fig_height))\n",
    "    axes = axes.flatten() if rows > 1 else [axes]\n",
    "    for i, col in enumerate(columns):\n",
    "        axes[i].boxplot(df[col])\n",
    "        axes[i].set_title(col)\n",
    "    for j in range(i+1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "box_plots_num_cols(train_df, num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T16:28:08.890952Z",
     "iopub.status.busy": "2024-10-29T16:28:08.890464Z",
     "iopub.status.idle": "2024-10-29T16:28:09.059425Z",
     "shell.execute_reply": "2024-10-29T16:28:09.058102Z",
     "shell.execute_reply.started": "2024-10-29T16:28:08.890904Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def remove_outliers(df: pd.DataFrame, cols: list[str], beta: float, cols_2: list[str] = None, beta2: float = None):\n",
    "    # Avoid deep copy unless truly needed to optimize memory usage\n",
    "    df_filtered = df.copy()\n",
    "    beta_dict = {col: beta2 if cols_2 and col in cols_2 and beta2 is not None else (6.0 if col == 'person_income' else beta) for col in cols}\n",
    "\n",
    "    for col in cols:\n",
    "        data = df_filtered[col]\n",
    "        \n",
    "        if data.empty:\n",
    "            print(f\"Column {col} is empty, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Use pandas quantile for faster percentile calculation\n",
    "        iqr = stats.iqr(data)\n",
    "        q1, q3 = data.quantile(0.25), data.quantile(0.75)\n",
    "        beta_val = beta_dict[col]\n",
    "        \n",
    "        print(f'{col} - beta: {beta_val}')\n",
    "        outlier_low = q1 - beta_val * iqr\n",
    "        outlier_high = q3 + beta_val * iqr\n",
    "        df_filtered = df_filtered[(data >= outlier_low) & (data <= outlier_high)]\n",
    "        \n",
    "    return df_filtered\n",
    "\n",
    "# Run with specified parameters\n",
    "df_clean = remove_outliers(train_df, num_cols, beta=1.5, cols_2=['loan_amnt'], beta2=3.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T16:28:11.450766Z",
     "iopub.status.busy": "2024-10-29T16:28:11.450215Z",
     "iopub.status.idle": "2024-10-29T16:28:11.595388Z",
     "shell.execute_reply": "2024-10-29T16:28:11.594149Z",
     "shell.execute_reply.started": "2024-10-29T16:28:11.450713Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def ins(indexx, clean_desc, orig_desc):\n",
    "    # Fetch the row for the current index without extra conversions\n",
    "    clean_values = clean_desc.loc[indexx].values\n",
    "    orig_values = orig_desc.loc[indexx].values\n",
    "    diff = orig_values - clean_values\n",
    "    # Create DataFrame once for both sets of values\n",
    "    res_df = pd.DataFrame({\n",
    "        'orig': orig_values, \n",
    "        'clean': clean_values,\n",
    "        'difference':diff\n",
    "    }, index=num_cols)\n",
    "    print(res_df.sort_values(by=['difference'], ascending=False, key= lambda x: abs(x)))\n",
    "\n",
    "# Compute describe() once for both DataFrames\n",
    "clean_desc = df_clean[num_cols].describe()\n",
    "orig_desc = train_df[num_cols].describe()\n",
    "\n",
    "# Loop through the index values\n",
    "for index in ['count', 'mean', 'std', 'min', 'max']:\n",
    "    \n",
    "    print(f'\\t\\t\\t{index.upper()}')\n",
    "    print('*' * 50)\n",
    "    ins(index, clean_desc, orig_desc)  # Pass precomputed descriptions\n",
    "    print('-' * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9709193,
     "sourceId": 84894,
     "sourceType": "competition"
    },
    {
     "datasetId": 4675026,
     "sourceId": 7949759,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
