{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.15","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":84894,"databundleVersionId":9709193,"sourceType":"competition"},{"sourceId":9706567,"sourceType":"datasetVersion","datasetId":5936521}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.idle":"2024-10-25T13:14:31.847106Z","shell.execute_reply.started":"2024-10-25T13:14:31.394661Z","shell.execute_reply":"2024-10-25T13:14:31.846337Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/playground-series-s4e10/sample_submission.csv\n/kaggle/input/playground-series-s4e10/train.csv\n/kaggle/input/playground-series-s4e10/test.csv\n/kaggle/input/study-dir/loan_status_study_xgb.db\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\n\n# Initialize TPU\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    tpu_strategy = tf.distribute.TPUStrategy(tpu)\n    print(\"TPU initialized successfully\")\nexcept Exception as e:\n    print(\"TPU initialization failed:\", e)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-25T13:14:32.616560Z","iopub.execute_input":"2024-10-25T13:14:32.616844Z","iopub.status.idle":"2024-10-25T13:14:42.808642Z","shell.execute_reply.started":"2024-10-25T13:14:32.616818Z","shell.execute_reply":"2024-10-25T13:14:42.807900Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"WARNING: Logging before InitGoogle() is written to STDERR\nE0000 00:00:1729862073.071314    7584 common_lib.cc:798] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n=== Source Location Trace: === \nlearning/45eac/tfrc/runtime/common_lib.cc:479\nD1025 13:14:33.079330655    7584 config.cc:196]                        gRPC EXPERIMENT call_status_override_on_cancellation   OFF (default:OFF)\nD1025 13:14:33.079343710    7584 config.cc:196]                        gRPC EXPERIMENT call_v3                                OFF (default:OFF)\nD1025 13:14:33.079347269    7584 config.cc:196]                        gRPC EXPERIMENT canary_client_privacy                  ON  (default:ON)\nD1025 13:14:33.079349737    7584 config.cc:196]                        gRPC EXPERIMENT capture_base_context                   ON  (default:ON)\nD1025 13:14:33.079352250    7584 config.cc:196]                        gRPC EXPERIMENT client_idleness                        ON  (default:ON)\nD1025 13:14:33.079354560    7584 config.cc:196]                        gRPC EXPERIMENT client_privacy                         ON  (default:ON)\nD1025 13:14:33.079356857    7584 config.cc:196]                        gRPC EXPERIMENT dapper_request_wire_size               OFF (default:OFF)\nD1025 13:14:33.079359097    7584 config.cc:196]                        gRPC EXPERIMENT empty_experiment                       OFF (default:OFF)\nD1025 13:14:33.079361280    7584 config.cc:196]                        gRPC EXPERIMENT event_engine_client                    OFF (default:OFF)\nD1025 13:14:33.079363451    7584 config.cc:196]                        gRPC EXPERIMENT event_engine_dns                       ON  (default:ON)\nD1025 13:14:33.079365720    7584 config.cc:196]                        gRPC EXPERIMENT event_engine_listener                  ON  (default:ON)\nD1025 13:14:33.079368018    7584 config.cc:196]                        gRPC EXPERIMENT free_large_allocator                   OFF (default:OFF)\nD1025 13:14:33.079370192    7584 config.cc:196]                        gRPC EXPERIMENT google_no_envelope_resolver            OFF (default:OFF)\nD1025 13:14:33.079372382    7584 config.cc:196]                        gRPC EXPERIMENT http2_stats_fix                        OFF (default:OFF)\nD1025 13:14:33.079374562    7584 config.cc:196]                        gRPC EXPERIMENT keepalive_fix                          OFF (default:OFF)\nD1025 13:14:33.079376758    7584 config.cc:196]                        gRPC EXPERIMENT keepalive_server_fix                   ON  (default:ON)\nD1025 13:14:33.079379114    7584 config.cc:196]                        gRPC EXPERIMENT loas_do_not_prefer_rekey_next_protocol OFF (default:OFF)\nD1025 13:14:33.079381367    7584 config.cc:196]                        gRPC EXPERIMENT loas_prod_to_cloud_prefer_pfs_ciphers  OFF (default:OFF)\nD1025 13:14:33.079383615    7584 config.cc:196]                        gRPC EXPERIMENT monitoring_experiment                  ON  (default:ON)\nD1025 13:14:33.079385885    7584 config.cc:196]                        gRPC EXPERIMENT multiping                              OFF (default:OFF)\nD1025 13:14:33.079388124    7584 config.cc:196]                        gRPC EXPERIMENT peer_state_based_framing               OFF (default:OFF)\nD1025 13:14:33.079390329    7584 config.cc:196]                        gRPC EXPERIMENT pending_queue_cap                      ON  (default:ON)\nD1025 13:14:33.079392655    7584 config.cc:196]                        gRPC EXPERIMENT pick_first_happy_eyeballs              ON  (default:ON)\nD1025 13:14:33.079394870    7584 config.cc:196]                        gRPC EXPERIMENT promise_based_client_call              OFF (default:OFF)\nD1025 13:14:33.079397041    7584 config.cc:196]                        gRPC EXPERIMENT promise_based_inproc_transport         OFF (default:OFF)\nD1025 13:14:33.079399190    7584 config.cc:196]                        gRPC EXPERIMENT promise_based_server_call              OFF (default:OFF)\nD1025 13:14:33.079401428    7584 config.cc:196]                        gRPC EXPERIMENT registered_method_lookup_in_transport  ON  (default:ON)\nD1025 13:14:33.079403679    7584 config.cc:196]                        gRPC EXPERIMENT rfc_max_concurrent_streams             ON  (default:ON)\nD1025 13:14:33.079406017    7584 config.cc:196]                        gRPC EXPERIMENT round_robin_delegate_to_pick_first     ON  (default:ON)\nD1025 13:14:33.079409252    7584 config.cc:196]                        gRPC EXPERIMENT rstpit                                 OFF (default:OFF)\nD1025 13:14:33.079411596    7584 config.cc:196]                        gRPC EXPERIMENT schedule_cancellation_over_write       OFF (default:OFF)\nD1025 13:14:33.079413961    7584 config.cc:196]                        gRPC EXPERIMENT server_privacy                         ON  (default:ON)\nD1025 13:14:33.079416418    7584 config.cc:196]                        gRPC EXPERIMENT tcp_frame_size_tuning                  OFF (default:OFF)\nD1025 13:14:33.079418617    7584 config.cc:196]                        gRPC EXPERIMENT tcp_rcv_lowat                          OFF (default:OFF)\nD1025 13:14:33.079420799    7584 config.cc:196]                        gRPC EXPERIMENT trace_record_callops                   OFF (default:OFF)\nD1025 13:14:33.079423011    7584 config.cc:196]                        gRPC EXPERIMENT unconstrained_max_quota_buffer_size    OFF (default:OFF)\nD1025 13:14:33.079425169    7584 config.cc:196]                        gRPC EXPERIMENT v3_backend_metric_filter               OFF (default:OFF)\nD1025 13:14:33.079427370    7584 config.cc:196]                        gRPC EXPERIMENT v3_channel_idle_filters                ON  (default:ON)\nD1025 13:14:33.079429642    7584 config.cc:196]                        gRPC EXPERIMENT v3_compression_filter                  ON  (default:ON)\nD1025 13:14:33.079431882    7584 config.cc:196]                        gRPC EXPERIMENT v3_server_auth_filter                  OFF (default:OFF)\nD1025 13:14:33.079434030    7584 config.cc:196]                        gRPC EXPERIMENT work_serializer_clears_time_cache      OFF (default:OFF)\nD1025 13:14:33.079436177    7584 config.cc:196]                        gRPC EXPERIMENT work_serializer_dispatch               OFF (default:OFF)\nD1025 13:14:33.079438395    7584 config.cc:196]                        gRPC EXPERIMENT write_size_cap                         ON  (default:ON)\nD1025 13:14:33.079440664    7584 config.cc:196]                        gRPC EXPERIMENT write_size_policy                      ON  (default:ON)\nD1025 13:14:33.079442976    7584 config.cc:196]                        gRPC EXPERIMENT wrr_delegate_to_pick_first             ON  (default:ON)\nI1025 13:14:33.079598401    7584 ev_epoll1_linux.cc:123]               grpc epoll fd: 59\nD1025 13:14:33.079609974    7584 ev_posix.cc:113]                      Using polling engine: epoll1\nD1025 13:14:33.090365928    7584 lb_policy_registry.cc:46]             registering LB policy factory for \"priority_experimental\"\nD1025 13:14:33.090375836    7584 lb_policy_registry.cc:46]             registering LB policy factory for \"outlier_detection_experimental\"\nD1025 13:14:33.090383373    7584 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_target_experimental\"\nD1025 13:14:33.090386781    7584 lb_policy_registry.cc:46]             registering LB policy factory for \"pick_first\"\nD1025 13:14:33.090389743    7584 lb_policy_registry.cc:46]             registering LB policy factory for \"round_robin\"\nD1025 13:14:33.090392556    7584 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_round_robin\"\nD1025 13:14:33.090420239    7584 lb_policy_registry.cc:46]             registering LB policy factory for \"grpclb\"\nD1025 13:14:33.090434775    7584 dns_resolver_plugin.cc:43]            Using EventEngine dns resolver\nD1025 13:14:33.090450775    7584 lb_policy_registry.cc:46]             registering LB policy factory for \"rls_experimental\"\nD1025 13:14:33.090472771    7584 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_manager_experimental\"\nD1025 13:14:33.090479915    7584 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_impl_experimental\"\nD1025 13:14:33.090483257    7584 lb_policy_registry.cc:46]             registering LB policy factory for \"cds_experimental\"\nD1025 13:14:33.090487030    7584 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_override_host_experimental\"\nD1025 13:14:33.090490123    7584 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_wrr_locality_experimental\"\nD1025 13:14:33.090493372    7584 lb_policy_registry.cc:46]             registering LB policy factory for \"ring_hash_experimental\"\nD1025 13:14:33.090499379    7584 certificate_provider_registry.cc:33]  registering certificate provider factory for \"file_watcher\"\nD1025 13:14:33.090527985    7584 channel_init.cc:157]                  Filter server-auth not registered, but is referenced in the after clause of grpc-server-authz when building channel stack SERVER_CHANNEL\nI1025 13:14:33.092268701    7584 ev_epoll1_linux.cc:359]               grpc epoll fd: 61\nI1025 13:14:33.093394308    7584 tcp_socket_utils.cc:689]              Disabling AF_INET6 sockets because ::1 is not available.\nI1025 13:14:33.104052524    7680 socket_utils_common_posix.cc:452]     Disabling AF_INET6 sockets because ::1 is not available.\nI1025 13:14:33.104114872    7680 socket_utils_common_posix.cc:379]     TCP_USER_TIMEOUT is available. TCP_USER_TIMEOUT will be used thereafter\nE1025 13:14:33.110193416    7584 oauth2_credentials.cc:238]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {created_time:\"2024-10-25T13:14:33.110178569+00:00\", grpc_status:2}\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\nINFO:tensorflow:Initializing the TPU system: local\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1729862078.535746    7584 service.cc:145] XLA service 0x5b0e2081ca20 initialized for platform TPU (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1729862078.535800    7584 service.cc:153]   StreamExecutor device (0): TPU, 2a886c8\nI0000 00:00:1729862078.535804    7584 service.cc:153]   StreamExecutor device (1): TPU, 2a886c8\nI0000 00:00:1729862078.535808    7584 service.cc:153]   StreamExecutor device (2): TPU, 2a886c8\nI0000 00:00:1729862078.535810    7584 service.cc:153]   StreamExecutor device (3): TPU, 2a886c8\nI0000 00:00:1729862078.535813    7584 service.cc:153]   StreamExecutor device (4): TPU, 2a886c8\nI0000 00:00:1729862078.535816    7584 service.cc:153]   StreamExecutor device (5): TPU, 2a886c8\nI0000 00:00:1729862078.535819    7584 service.cc:153]   StreamExecutor device (6): TPU, 2a886c8\nI0000 00:00:1729862078.535822    7584 service.cc:153]   StreamExecutor device (7): TPU, 2a886c8\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Finished initializing TPU system.\nINFO:tensorflow:Found TPU system:\nINFO:tensorflow:*** Num TPU Cores: 8\nINFO:tensorflow:*** Num TPU Workers: 1\nINFO:tensorflow:*** Num TPU Cores Per Worker: 8\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\nTPU initialized successfully\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\nprint(f'reading the csv files into pandas dataframes.')\ntrain_df = pd.read_csv('/kaggle/input/playground-series-s4e10/train.csv')\ntest_df = pd.read_csv('/kaggle/input/playground-series-s4e10/test.csv')\nsub_df = pd.read_csv('/kaggle/input/playground-series-s4e10/sample_submission.csv')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-25T13:11:47.625684Z","iopub.execute_input":"2024-10-25T13:11:47.626427Z","iopub.status.idle":"2024-10-25T13:11:47.758906Z","shell.execute_reply.started":"2024-10-25T13:11:47.626393Z","shell.execute_reply":"2024-10-25T13:11:47.758005Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"reading the csv files into pandas dataframes.\n","output_type":"stream"}]},{"cell_type":"code","source":"# train_df.info()","metadata":{"execution":{"iopub.status.busy":"2024-10-25T13:11:47.760434Z","iopub.execute_input":"2024-10-25T13:11:47.760819Z","iopub.status.idle":"2024-10-25T13:11:47.764138Z","shell.execute_reply.started":"2024-10-25T13:11:47.760790Z","shell.execute_reply":"2024-10-25T13:11:47.763324Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# test_df.info()","metadata":{"execution":{"iopub.status.busy":"2024-10-25T13:11:47.765062Z","iopub.execute_input":"2024-10-25T13:11:47.765302Z","iopub.status.idle":"2024-10-25T13:11:47.773908Z","shell.execute_reply.started":"2024-10-25T13:11:47.765277Z","shell.execute_reply":"2024-10-25T13:11:47.773198Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# train_df.isnull().any(), test_df.isnull().any()","metadata":{"execution":{"iopub.status.busy":"2024-10-25T13:11:47.775384Z","iopub.execute_input":"2024-10-25T13:11:47.775688Z","iopub.status.idle":"2024-10-25T13:11:47.781995Z","shell.execute_reply.started":"2024-10-25T13:11:47.775664Z","shell.execute_reply":"2024-10-25T13:11:47.781365Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"cat_cols = train_df.select_dtypes('object').columns\nnum_cols = []\nfor col in train_df.select_dtypes(exclude='object').columns:\n    if col not in ('id', 'loan_status'):\n        num_cols.append(col)\n# num_cols, cat_cols","metadata":{"execution":{"iopub.status.busy":"2024-10-25T13:11:47.782771Z","iopub.execute_input":"2024-10-25T13:11:47.783027Z","iopub.status.idle":"2024-10-25T13:11:47.793461Z","shell.execute_reply.started":"2024-10-25T13:11:47.783001Z","shell.execute_reply":"2024-10-25T13:11:47.792712Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# train_df['loan_status'].value_counts(normalize=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-25T13:11:47.794365Z","iopub.execute_input":"2024-10-25T13:11:47.794644Z","iopub.status.idle":"2024-10-25T13:11:47.801406Z","shell.execute_reply.started":"2024-10-25T13:11:47.794619Z","shell.execute_reply":"2024-10-25T13:11:47.800745Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef box_plots_num_cols(df, columns):\n    df = df.copy()\n    base_width = 10\n    base_height = 5\n    rows = len(columns) \n    cols = 1\n    fig_width = cols * base_width\n    fig_height = rows * base_height\n    fig, axes = plt.subplots(rows, cols, figsize=(fig_width, fig_height))\n    axes = axes.flatten() if rows > 1 else [axes]\n    for i, col in enumerate(columns):\n        axes[i].boxplot(df[col])  \n        axes[i].set_title(col)\n    for j in range(i+1, len(axes)):\n        axes[j].axis('off')\n    plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2024-10-25T13:11:47.802225Z","iopub.execute_input":"2024-10-25T13:11:47.802463Z","iopub.status.idle":"2024-10-25T13:11:48.122755Z","shell.execute_reply.started":"2024-10-25T13:11:47.802421Z","shell.execute_reply":"2024-10-25T13:11:48.121908Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# box_plots_num_cols(train_df, num_cols)","metadata":{"execution":{"iopub.status.busy":"2024-10-25T13:11:48.123751Z","iopub.execute_input":"2024-10-25T13:11:48.124041Z","iopub.status.idle":"2024-10-25T13:11:48.127059Z","shell.execute_reply.started":"2024-10-25T13:11:48.124013Z","shell.execute_reply":"2024-10-25T13:11:48.126379Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from scipy import stats\nimport numpy as np\n\ndef remove_outliers(df:pd.DataFrame(), cols, beta):\n    df = df.copy()\n    for col in cols:\n#         print(f'removing {col} outliers:\\n')\n        data = df[col]\n        iqr = stats.iqr(data)\n        q1 = np.percentile(data, 25)\n        q3 = np.percentile(data, 75)\n        outlier_low = q1 - beta * iqr\n        outlier_high = q1 + beta * iqr\n#         print(f'outlier_low:{outlier_low}, outlier_high: {outlier_high}')\n        df = df[(data >= outlier_low) & (data <= outlier_high)]\n    return df\n","metadata":{"execution":{"iopub.status.busy":"2024-10-25T13:11:48.127790Z","iopub.execute_input":"2024-10-25T13:11:48.128035Z","iopub.status.idle":"2024-10-25T13:11:48.418537Z","shell.execute_reply.started":"2024-10-25T13:11:48.128012Z","shell.execute_reply":"2024-10-25T13:11:48.417653Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(f'removing outliers before oversampling')\ndf_clean = remove_outliers(train_df, num_cols, 1.5)\n# box_plots_num_cols(df_clean, num_cols)\ndf_clean.shape, train_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-25T13:11:48.421649Z","iopub.execute_input":"2024-10-25T13:11:48.422119Z","iopub.status.idle":"2024-10-25T13:11:48.468661Z","shell.execute_reply.started":"2024-10-25T13:11:48.422086Z","shell.execute_reply":"2024-10-25T13:11:48.467957Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"removing outliers before oversampling\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"((24802, 13), (58645, 13))"},"metadata":{}}]},{"cell_type":"code","source":"def hist_plot_cat_cols(df:pd.DataFrame(), cat_cols=cat_cols):\n    df = df.copy()\n    fig, axes_cat = plt.subplots(1, len(cat_cols), figsize=(20, 10))\n    for i, col in enumerate(cat_cols):\n        axes_cat[i].hist(df[col])\n        axes_cat[i].set_title(col)","metadata":{"execution":{"iopub.status.busy":"2024-10-25T13:11:48.469516Z","iopub.execute_input":"2024-10-25T13:11:48.469767Z","iopub.status.idle":"2024-10-25T13:11:48.474475Z","shell.execute_reply.started":"2024-10-25T13:11:48.469743Z","shell.execute_reply":"2024-10-25T13:11:48.473702Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# hist_plot_cat_cols(train_df)","metadata":{"execution":{"iopub.status.busy":"2024-10-25T13:11:48.475365Z","iopub.execute_input":"2024-10-25T13:11:48.475729Z","iopub.status.idle":"2024-10-25T13:11:48.486953Z","shell.execute_reply.started":"2024-10-25T13:11:48.475704Z","shell.execute_reply":"2024-10-25T13:11:48.486244Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# hist_plot_cat_cols(df_clean)","metadata":{"execution":{"iopub.status.busy":"2024-10-25T13:11:48.487756Z","iopub.execute_input":"2024-10-25T13:11:48.488070Z","iopub.status.idle":"2024-10-25T13:11:48.496017Z","shell.execute_reply.started":"2024-10-25T13:11:48.488046Z","shell.execute_reply":"2024-10-25T13:11:48.495405Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n\nprint('encoding the categorical features')\ndf_clean = df_clean.drop(columns=['id'])\n\nord_enc = OrdinalEncoder()\none_hot_enc = OneHotEncoder(sparse_output=False)\n\nordinal_cols = ['loan_grade']\none_hot_cols = [col for col in cat_cols if col != 'loan_grade']\nremaining_cols = [col for col in df_clean.columns if col not in cat_cols]\n\nencoder = ColumnTransformer(\n            transformers=[\n                ('ordinal_encoder', ord_enc, ordinal_cols),\n                ('one_hot_encoder', one_hot_enc, one_hot_cols),\n                ('passthrough', 'passthrough', remaining_cols )\n            ]\n)\n\nencoded_data = encoder.fit_transform(df_clean)\none_hot_enc.fit(df_clean[one_hot_cols])\none_hot_encoded_cols = one_hot_enc.get_feature_names_out(one_hot_cols)\nall_cols = ordinal_cols + list(one_hot_encoded_cols) + remaining_cols\ndf_encoded = pd.DataFrame(encoded_data, columns=all_cols)\ndf_encoded.info()","metadata":{"execution":{"iopub.status.busy":"2024-10-25T13:11:48.496787Z","iopub.execute_input":"2024-10-25T13:11:48.497033Z","iopub.status.idle":"2024-10-25T13:11:48.588120Z","shell.execute_reply.started":"2024-10-25T13:11:48.497010Z","shell.execute_reply":"2024-10-25T13:11:48.587353Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"encoding the categorical features\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 24802 entries, 0 to 24801\nData columns (total 21 columns):\n #   Column                          Non-Null Count  Dtype  \n---  ------                          --------------  -----  \n 0   loan_grade                      24802 non-null  float64\n 1   person_home_ownership_MORTGAGE  24802 non-null  float64\n 2   person_home_ownership_OTHER     24802 non-null  float64\n 3   person_home_ownership_OWN       24802 non-null  float64\n 4   person_home_ownership_RENT      24802 non-null  float64\n 5   loan_intent_DEBTCONSOLIDATION   24802 non-null  float64\n 6   loan_intent_EDUCATION           24802 non-null  float64\n 7   loan_intent_HOMEIMPROVEMENT     24802 non-null  float64\n 8   loan_intent_MEDICAL             24802 non-null  float64\n 9   loan_intent_PERSONAL            24802 non-null  float64\n 10  loan_intent_VENTURE             24802 non-null  float64\n 11  cb_person_default_on_file_N     24802 non-null  float64\n 12  cb_person_default_on_file_Y     24802 non-null  float64\n 13  person_age                      24802 non-null  float64\n 14  person_income                   24802 non-null  float64\n 15  person_emp_length               24802 non-null  float64\n 16  loan_amnt                       24802 non-null  float64\n 17  loan_int_rate                   24802 non-null  float64\n 18  loan_percent_income             24802 non-null  float64\n 19  cb_person_cred_hist_length      24802 non-null  float64\n 20  loan_status                     24802 non-null  float64\ndtypes: float64(21)\nmemory usage: 4.0 MB\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install imblearn\nfrom imblearn.over_sampling import SMOTE, SVMSMOTE\n\nprint(f'oversampling using SVMSMOTE')\ndf_enc_copy = df_encoded.copy()\n\nsmote = SMOTE(random_state=32,  k_neighbors=10)\nsvm_smote = SVMSMOTE(random_state=32, k_neighbors=10,m_neighbors=10)\n\nX = df_enc_copy.drop(columns=['loan_status'])\ny = df_enc_copy.loc[:, 'loan_status']\n\nX_smote, y_smote = smote.fit_resample(X, y)\nX_svm_smote, y_svm_smote = svm_smote.fit_resample(X, y)\nX_smote.shape, y_smote.shape, X_svm_smote.shape, y_svm_smote.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-25T13:11:48.589001Z","iopub.execute_input":"2024-10-25T13:11:48.589349Z","iopub.status.idle":"2024-10-25T13:11:56.279552Z","shell.execute_reply.started":"2024-10-25T13:11:48.589322Z","shell.execute_reply":"2024-10-25T13:11:56.278410Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Requirement already satisfied: imblearn in /usr/local/lib/python3.10/site-packages (0.0)\nRequirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/site-packages (from imblearn) (0.12.4)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.26.4)\nRequirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.5.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (3.5.0)\nRequirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.14.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\noversampling using SVMSMOTE\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"((46192, 20), (46192,), (46192, 20), (46192,))"},"metadata":{}}]},{"cell_type":"code","source":"smote_df = X_smote\nsmote_df['loan_status'] = y_smote\n\nsvm_smote_df = X_svm_smote\nsvm_smote_df['loan_status'] = y_svm_smote\n","metadata":{"execution":{"iopub.status.busy":"2024-10-25T13:11:56.280973Z","iopub.execute_input":"2024-10-25T13:11:56.281497Z","iopub.status.idle":"2024-10-25T13:11:56.287097Z","shell.execute_reply.started":"2024-10-25T13:11:56.281462Z","shell.execute_reply":"2024-10-25T13:11:56.286308Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# c = [col for col in smote_df.columns if col not in one_hot_encoded_cols]\n# box_plots_num_cols(smote_df, c)","metadata":{"execution":{"iopub.status.busy":"2024-10-25T13:11:56.288152Z","iopub.execute_input":"2024-10-25T13:11:56.288597Z","iopub.status.idle":"2024-10-25T13:11:56.310776Z","shell.execute_reply.started":"2024-10-25T13:11:56.288565Z","shell.execute_reply":"2024-10-25T13:11:56.310077Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# c2 = [col for col in svm_smote_df.columns if col not in one_hot_encoded_cols]\n# box_plots_num_cols(svm_smote_df, c2)","metadata":{"execution":{"iopub.status.busy":"2024-10-25T13:11:56.311718Z","iopub.execute_input":"2024-10-25T13:11:56.311984Z","iopub.status.idle":"2024-10-25T13:11:56.328035Z","shell.execute_reply.started":"2024-10-25T13:11:56.311957Z","shell.execute_reply":"2024-10-25T13:11:56.327346Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# smote_corr = smote_df.corr()\n# svm_smote_corr = svm_smote_df.corr()","metadata":{"execution":{"iopub.status.busy":"2024-10-25T13:11:56.328937Z","iopub.execute_input":"2024-10-25T13:11:56.329193Z","iopub.status.idle":"2024-10-25T13:11:56.345108Z","shell.execute_reply.started":"2024-10-25T13:11:56.329168Z","shell.execute_reply":"2024-10-25T13:11:56.344371Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n\ndef heatmap_corr(corr):\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n    plt.title('Correlation Heatmap')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-25T13:11:56.346066Z","iopub.execute_input":"2024-10-25T13:11:56.346366Z","iopub.status.idle":"2024-10-25T13:11:56.395131Z","shell.execute_reply.started":"2024-10-25T13:11:56.346322Z","shell.execute_reply":"2024-10-25T13:11:56.394374Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# heatmap_corr(smote_corr)","metadata":{"execution":{"iopub.status.busy":"2024-10-25T13:11:56.395943Z","iopub.execute_input":"2024-10-25T13:11:56.396342Z","iopub.status.idle":"2024-10-25T13:11:56.399329Z","shell.execute_reply.started":"2024-10-25T13:11:56.396316Z","shell.execute_reply":"2024-10-25T13:11:56.398661Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# heatmap_corr(svm_smote_corr)","metadata":{"execution":{"iopub.status.busy":"2024-10-25T13:11:56.400182Z","iopub.execute_input":"2024-10-25T13:11:56.400434Z","iopub.status.idle":"2024-10-25T13:11:56.409533Z","shell.execute_reply.started":"2024-10-25T13:11:56.400409Z","shell.execute_reply":"2024-10-25T13:11:56.408890Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# high_smote_corr = smote_corr[(abs(smote_corr) > 0.7) & (abs(smote_corr) != 1.0)]\n# heatmap_corr(high_smote_corr)","metadata":{"execution":{"iopub.status.busy":"2024-10-25T13:11:56.410313Z","iopub.execute_input":"2024-10-25T13:11:56.410568Z","iopub.status.idle":"2024-10-25T13:11:56.423334Z","shell.execute_reply.started":"2024-10-25T13:11:56.410543Z","shell.execute_reply":"2024-10-25T13:11:56.422585Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# high_svm_smote_corr = svm_smote_corr[(abs(svm_smote_corr) > 0.7) & (abs(svm_smote_corr) != 1.0)]\n# heatmap_corr(high_svm_smote_corr)","metadata":{"execution":{"iopub.status.busy":"2024-10-25T13:11:56.424291Z","iopub.execute_input":"2024-10-25T13:11:56.424553Z","iopub.status.idle":"2024-10-25T13:11:56.433086Z","shell.execute_reply.started":"2024-10-25T13:11:56.424526Z","shell.execute_reply":"2024-10-25T13:11:56.432408Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"print('dropping the column person home ownership rent')\ndf_final = svm_smote_df.drop(columns=[ 'person_home_ownership_RENT'])\ndf_final.info()","metadata":{"execution":{"iopub.status.busy":"2024-10-25T13:11:56.433924Z","iopub.execute_input":"2024-10-25T13:11:56.434165Z","iopub.status.idle":"2024-10-25T13:11:56.456033Z","shell.execute_reply.started":"2024-10-25T13:11:56.434141Z","shell.execute_reply":"2024-10-25T13:11:56.455325Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"dropping the column person home ownership rent\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 46192 entries, 0 to 46191\nData columns (total 20 columns):\n #   Column                          Non-Null Count  Dtype  \n---  ------                          --------------  -----  \n 0   loan_grade                      46192 non-null  float64\n 1   person_home_ownership_MORTGAGE  46192 non-null  float64\n 2   person_home_ownership_OTHER     46192 non-null  float64\n 3   person_home_ownership_OWN       46192 non-null  float64\n 4   loan_intent_DEBTCONSOLIDATION   46192 non-null  float64\n 5   loan_intent_EDUCATION           46192 non-null  float64\n 6   loan_intent_HOMEIMPROVEMENT     46192 non-null  float64\n 7   loan_intent_MEDICAL             46192 non-null  float64\n 8   loan_intent_PERSONAL            46192 non-null  float64\n 9   loan_intent_VENTURE             46192 non-null  float64\n 10  cb_person_default_on_file_N     46192 non-null  float64\n 11  cb_person_default_on_file_Y     46192 non-null  float64\n 12  person_age                      46192 non-null  float64\n 13  person_income                   46192 non-null  float64\n 14  person_emp_length               46192 non-null  float64\n 15  loan_amnt                       46192 non-null  float64\n 16  loan_int_rate                   46192 non-null  float64\n 17  loan_percent_income             46192 non-null  float64\n 18  cb_person_cred_hist_length      46192 non-null  float64\n 19  loan_status                     46192 non-null  float64\ndtypes: float64(20)\nmemory usage: 7.0 MB\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\n\nprint('splitting the dataset into train and test')\n\nsss = StratifiedShuffleSplit(n_splits=1, random_state=32, test_size=0.1)\nfor tr, te in sss.split(X, y):\n    df_train = df_final.iloc[tr]\n    df_test  = df_final.iloc[te]\ntarget_col = 'loan_status'\nfeatures_cols = [col for col in df_train.columns if col != target_col]\ndf_train.shape, df_test.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-25T13:11:56.456840Z","iopub.execute_input":"2024-10-25T13:11:56.457086Z","iopub.status.idle":"2024-10-25T13:11:56.478396Z","shell.execute_reply.started":"2024-10-25T13:11:56.457062Z","shell.execute_reply":"2024-10-25T13:11:56.477610Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"splitting the dataset into train and test\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"((22321, 20), (2481, 20))"},"metadata":{}}]},{"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures\nfrom sklearn.pipeline import Pipeline\n\ndef prepare_data_for_tpu(df:pd.DataFrame, features_cols:list[str], target_col:str, batch_size:int=32, poly_degree:int=2, poly:bool=False, valid_split:bool=False,valid_split_size:float=0.2):\n\n    df = df.copy()\n    features = df[features_cols]\n    target = df.loc[:, target_col]\n\n    pipe = Pipeline([\n        ('scaler', StandardScaler()),\n        ('poly', PolynomialFeatures(degree=poly_degree, include_bias=False, interaction_only=True)) if poly else None\n    ])\n    pipe.steps = [step for step in pipe.steps if step is not None]\n\n    features_final = pipe.fit_transform(features)\n    features_final_df = pd.DataFrame(features_final, columns=[f'feature_{i}' for i in range(features_final.shape[1])])\n\n\n    dataset = tf.data.Dataset.from_tensor_slices((dict(features_final_df), target))\n    \n    dataset_size = len(features)\n    val_size = int(valid_split_size * dataset_size)\n    if valid_split and (valid_split_size > 0.0):\n        valid_dataset = dataset.take(val_size).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n        train_dataset = dataset.skip(val_size).shuffle(buffer_size=dataset_size-val_size).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n        \n        result = (train_dataset, valid_dataset)\n    else:\n        dataset = dataset.shuffle(buffer_size=dataset_size).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n        \n        result = (dataset, )\n    return result\n\ntrain_dataset, valid_dataset = prepare_data_for_tpu(df_train, features_cols=features_cols, target_col=target_col, poly=True, poly_degree=3, valid_split=True, valid_split_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-10-25T13:11:56.479364Z","iopub.execute_input":"2024-10-25T13:11:56.479639Z","iopub.status.idle":"2024-10-25T13:11:58.510434Z","shell.execute_reply.started":"2024-10-25T13:11:56.479611Z","shell.execute_reply":"2024-10-25T13:11:58.509610Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport keras \nfrom keras import activations, layers, initializers, regularizers, optimizers, losses, metrics\n\nclass ann_layer_gen:\n    def __init__(self, input_shape, batch_norm:bool=False, drop_out:bool=False, regularize:bool=False,  initiliazers:bool=False,drop_out_rate:float=0.0) -> None:\n        self.input_shape = input_shape\n        self.batch_norm = batch_norm\n        self.drop_out = drop_out\n        self.regularize = regularize\n        self.initiliazers = initiliazers\n        self.drop_out_rate = drop_out_rate\n        self.model = keras.Sequential()\n        self.model.add(keras.Input(shape=(input_shape, )))\n    \n    def __call__(self,  out_act_fun:activations, out_unit:int, units:int=100, n_hidden_layers:int=5,  hidden_act_fun:activations=activations.relu) -> keras.Sequential :\n        for n_layer in range(1, n_hidden_layers+1):\n            layer_params = {'units':units, 'activation':hidden_act_fun}\n            \n            if self.regularize:\n                layer_params['kernel_regularizer'] = regularizers.L1()\n            if self.initiliazers:\n                layer_params['kernel_initiliazer'] = initializers.glorot_normal\n            \n            self.model.add(layers.Dense(**layer_params))\n\n            if self.drop_out:\n                self.model.add(layers.Dropout(rate=self.drop_out_rate))\n\n            if self.batch_norm:\n                self.model.add(layers.BatchNormalization())\n            \n            units = round(units / 2)\n        self.model.add(layers.Dense(out_unit, activation=out_act_fun))\n        return self.model\n    \n    def compile(model, loss:losses.Loss, metrics:list=['accuracy'], optimizer:optimizers.Optimizer=optimizers.Adam, valid_split:float=0.2, learning_rate:float=0.01 ) -> keras.Sequential:\n        try:\n            model.compile(optimizer=optimizer(learning_rate=learning_rate), loss=loss, metrics=metrics)\n        except Exception as e:\n            print('Could not compile the model with given params.')\n        return model","metadata":{"execution":{"iopub.status.busy":"2024-10-25T13:11:58.513808Z","iopub.execute_input":"2024-10-25T13:11:58.514124Z","iopub.status.idle":"2024-10-25T13:11:58.523057Z","shell.execute_reply.started":"2024-10-25T13:11:58.514090Z","shell.execute_reply":"2024-10-25T13:11:58.522379Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"import optuna\nfrom keras import optimizers, activations, losses\nimport tensorflow as tf\nfrom keras import backend as K\n\n# Objective function for Optuna\ndef objective(trial: optuna.Trial):\n    \n    epochs = trial.suggest_int('epochs', 10, 100, step=10)\n    units = trial.suggest_int('units', 100, 500, step=50)\n    n_hidden_layers = trial.suggest_int('n_hidden_layers', 3, 20, step=2)\n    batch_norm = trial.suggest_categorical('batch_norm', [True, False])\n    drop_out = trial.suggest_categorical('drop_out', [True, False])\n    regularize = trial.suggest_categorical('regularize', [True, False])\n    initializers = trial.suggest_categorical('initializers', [True, False])\n    drop_out_rate = trial.suggest_float('drop_out_rate', 0, 1)\n    learning_rate = trial.suggest_float('learning_rate', 1e-6, 1e-1, log=True)\n    \n    # Optimizer selection\n    optimizers_list = [\n        optimizers.Adam(learning_rate), \n        optimizers.RMSprop(learning_rate), \n        optimizers.SGD(learning_rate), \n        optimizers.Nadam(learning_rate)\n    ]\n    optimizer = trial.suggest_categorical('optimizer', optimizers_list)\n\n    # Initialization parameters\n    init_params = {\n        'batch_norm': batch_norm,\n        'drop_out': drop_out,\n        'drop_out_rate': drop_out_rate,\n        'regularize': regularize,\n        'initializers': initializers\n    }\n\n    # Model creation within TPU scope\n    with tpu_strategy.scope():\n        ann_layer_generator = ann_layer_gen(input_shape=X_train.shape[1], **init_params)\n        ann_model = ann_layer_generator(out_act_fun=activations.sigmoid, out_unit=1, units=units, n_hidden_layers=n_hidden_layers)\n        ann_model.compile(optimizer=optimizer, loss=losses.binary_crossentropy, metrics=['accuracy'], steps_per_execution=32)\n    \n    batch_size = 8 * tpu_strategy.num_replicas_in_sync\n    \n    # Model training\n    history = ann_model.fit(train_dataset, validation_data=valid_dataset, batch_size=batch_size, epochs=epochs, validation_split=0.1, shuffle=True)\n    val_accuracy = history.history['val_accuracy'][-1] \n    return val_accuracy\n","metadata":{"execution":{"iopub.status.busy":"2024-10-25T13:12:50.496700Z","iopub.execute_input":"2024-10-25T13:12:50.497512Z","iopub.status.idle":"2024-10-25T13:12:50.506591Z","shell.execute_reply.started":"2024-10-25T13:12:50.497476Z","shell.execute_reply":"2024-10-25T13:12:50.505780Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"\nloan_approval_ann_study = optuna.create_study(\n    storage='sqlite:///loan_approval_ann_study.db',\n    study_name='loan_approval_ann_study',\n    direction='maximize',\n    sampler=optuna.samplers.TPESampler,\n    load_if_exists=True\n)\n\nloan_approval_ann_study.optimize(objective, n_trials=10, show_progress_bar=True, n_jobs=-1)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-25T13:12:55.104692Z","iopub.execute_input":"2024-10-25T13:12:55.105049Z","iopub.status.idle":"2024-10-25T13:12:55.149047Z","shell.execute_reply.started":"2024-10-25T13:12:55.105021Z","shell.execute_reply":"2024-10-25T13:12:55.148174Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"[I 2024-10-25 13:12:55,137] Using an existing study with name 'loan_approval_ann_study' instead of creating a new one.\n  0%|          | 0/10 [00:00<?, ?it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n\n\nprint('encoding the final test data set')\nord_enc_test = OrdinalEncoder()\none_hot_enc_test = OneHotEncoder(sparse_output=False)\n\ntest_cat_cols = test_df.select_dtypes('object').columns\nordinal_cols = ['loan_grade']\none_hot_cols = [col for col in test_cat_cols if col != 'loan_grade']\nremaining_cols = [col for col in test_df.columns if col not in list(test_cat_cols)]\n\nencoder_test = ColumnTransformer(\n            transformers=[\n                ('ordinal_encoder', ord_enc_test, ordinal_cols),\n                ('one_hot_encoder', one_hot_enc_test, one_hot_cols),\n                ('passthrough', 'passthrough', remaining_cols )\n            ]\n)\n\nencoded_data = encoder_test.fit_transform(test_df)\none_hot_enc_test.fit(test_df[one_hot_cols])\none_hot_encoded_cols = one_hot_enc_test.get_feature_names_out(one_hot_cols)\nall_cols = ordinal_cols + list(one_hot_encoded_cols) + remaining_cols\ntest_df_encoded = pd.DataFrame(encoded_data, columns=all_cols)\ntest_df_encoded.info()","metadata":{"execution":{"iopub.status.busy":"2024-10-25T13:11:58.956757Z","iopub.execute_input":"2024-10-25T13:11:58.956998Z","iopub.status.idle":"2024-10-25T13:11:59.023737Z","shell.execute_reply.started":"2024-10-25T13:11:58.956973Z","shell.execute_reply":"2024-10-25T13:11:59.022857Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"encoding the final test data set\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 39098 entries, 0 to 39097\nData columns (total 21 columns):\n #   Column                          Non-Null Count  Dtype  \n---  ------                          --------------  -----  \n 0   loan_grade                      39098 non-null  float64\n 1   person_home_ownership_MORTGAGE  39098 non-null  float64\n 2   person_home_ownership_OTHER     39098 non-null  float64\n 3   person_home_ownership_OWN       39098 non-null  float64\n 4   person_home_ownership_RENT      39098 non-null  float64\n 5   loan_intent_DEBTCONSOLIDATION   39098 non-null  float64\n 6   loan_intent_EDUCATION           39098 non-null  float64\n 7   loan_intent_HOMEIMPROVEMENT     39098 non-null  float64\n 8   loan_intent_MEDICAL             39098 non-null  float64\n 9   loan_intent_PERSONAL            39098 non-null  float64\n 10  loan_intent_VENTURE             39098 non-null  float64\n 11  cb_person_default_on_file_N     39098 non-null  float64\n 12  cb_person_default_on_file_Y     39098 non-null  float64\n 13  id                              39098 non-null  float64\n 14  person_age                      39098 non-null  float64\n 15  person_income                   39098 non-null  float64\n 16  person_emp_length               39098 non-null  float64\n 17  loan_amnt                       39098 non-null  float64\n 18  loan_int_rate                   39098 non-null  float64\n 19  loan_percent_income             39098 non-null  float64\n 20  cb_person_cred_hist_length      39098 non-null  float64\ndtypes: float64(21)\nmemory usage: 6.3 MB\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures\nfrom sklearn.pipeline import Pipeline\n\ndef prepare_test_data_for_tpu(df: pd.DataFrame, features_cols: list[str], target_col: str, batch_size: int = 32, poly_degree: int = 2, poly: bool = False):\n    \n    df = df.copy()\n    features = df[features_cols]\n    target = df[target_col]\n\n    # Define pipeline for scaling and optional polynomial features\n    pipe = Pipeline([\n        ('scaler', StandardScaler()),\n        ('poly', PolynomialFeatures(degree=poly_degree, include_bias=False, interaction_only=True)) if poly else None\n    ])\n    pipe.steps = [step for step in pipe.steps if step is not None]\n\n    # Transform features\n    features_final = pipe.fit_transform(features)\n    features_final_df = pd.DataFrame(features_final, columns=[f'feature_{i}' for i in range(features_final.shape[1])])\n\n    # Create tf.data.Dataset without shuffling, batching only\n    dataset = tf.data.Dataset.from_tensor_slices((dict(features_final_df), target))\n    dataset = dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n\n    return dataset\n","metadata":{"execution":{"iopub.status.busy":"2024-10-25T13:11:59.024808Z","iopub.execute_input":"2024-10-25T13:11:59.025124Z","iopub.status.idle":"2024-10-25T13:11:59.031287Z","shell.execute_reply.started":"2024-10-25T13:11:59.025093Z","shell.execute_reply":"2024-10-25T13:11:59.030585Z"},"trusted":true},"execution_count":34,"outputs":[]}]}