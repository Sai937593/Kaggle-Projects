{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":86473,"databundleVersionId":9805518,"sourceType":"competition"}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-23T15:06:58.334753Z","iopub.execute_input":"2024-12-23T15:06:58.335065Z","iopub.status.idle":"2024-12-23T15:06:58.638968Z","shell.execute_reply.started":"2024-12-23T15:06:58.335028Z","shell.execute_reply":"2024-12-23T15:06:58.638145Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/dsaa-6100-movie-review-sentiment-classification/test_data.csv\n/kaggle/input/dsaa-6100-movie-review-sentiment-classification/movie_reviews/movie_reviews.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\n\ndf_train = pd.read_csv('/kaggle/input/dsaa-6100-movie-review-sentiment-classification/movie_reviews/movie_reviews.csv')\ndf_test = pd.read_csv('/kaggle/input/dsaa-6100-movie-review-sentiment-classification/test_data.csv')\n\ndf_train.shape, df_test.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T15:55:01.626851Z","iopub.execute_input":"2024-12-23T15:55:01.627170Z","iopub.status.idle":"2024-12-23T15:55:03.534311Z","shell.execute_reply.started":"2024-12-23T15:55:01.627147Z","shell.execute_reply":"2024-12-23T15:55:03.533349Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"((40000, 2), (10000, 2))"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"import re\n\ndef clean_text(text):\n    t = text.lower()\n    t = re.sub(r'[^A-Za-z\\s]', '', t)\n    return t\n\ndef create_vocab(text:str, vocab:list=None, max_words=100):\n    if vocab is None:\n        print('intialize the vocab list')\n        return\n    text = clean_text(text)\n    words = [word for word in text.split(' ') if word]\n    final_words = []\n    for word in words:\n        if word not in vocab:\n            final_words.append(word)\n    \n    vocab.extend(final_words)\n    return vocab\n\ndef encode_text(text:str, vocab:list, min_len=10):\n    txt_ids = []\n    text = clean_text(text)\n    words = [word for word in text.split(' ') if word]\n    for word in words:  \n        id = vocab.index(word)\n        txt_ids.append(id)\n    padding = abs(min_len - len(txt_ids))\n    \n    if len(txt_ids) < min_len:\n        txt_ids = txt_ids + [0] * padding\n    elif len(txt_ids) > min_len:\n        txt_ids = txt_ids[:min_len]\n    return txt_ids\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T05:15:52.993311Z","iopub.execute_input":"2024-12-24T05:15:52.993664Z","iopub.status.idle":"2024-12-24T05:15:53.000270Z","shell.execute_reply.started":"2024-12-24T05:15:52.993637Z","shell.execute_reply":"2024-12-24T05:15:52.999396Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"import numpy as np\nimport re\n\nmax_len = 0\n\n\nfor text in df_train['text']:\n    clean = clean_text(text)\n    words = [word for word in clean.split(' ') if word]\n    if len(words) > max_len:\n        max_len = len(words)\n\nprint(max_len)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T16:01:04.001122Z","iopub.execute_input":"2024-12-23T16:01:04.001470Z","iopub.status.idle":"2024-12-23T16:01:05.637135Z","shell.execute_reply.started":"2024-12-23T16:01:04.001423Z","shell.execute_reply":"2024-12-23T16:01:05.636268Z"}},"outputs":[{"name":"stdout","text":"2450\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"vocab=[]\nfor text in df_train['text']:\n    vocab=create_vocab(text, vocab)\nlen(vocab)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pickle \n\nwith open('/kaggle/working/vocab.pkl', 'rb') as f:\n    vocab = pickle.load(f)\n\nprint(len(vocab))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T05:09:50.194342Z","iopub.execute_input":"2024-12-24T05:09:50.194710Z","iopub.status.idle":"2024-12-24T05:09:50.222690Z","shell.execute_reply.started":"2024-12-24T05:09:50.194679Z","shell.execute_reply":"2024-12-24T05:09:50.221746Z"}},"outputs":[{"name":"stdout","text":"159227\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"import pandas as pd\n\ndf_train = pd.read_csv('/kaggle/input/dsaa-6100-movie-review-sentiment-classification/movie_reviews/movie_reviews.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T05:12:25.258895Z","iopub.execute_input":"2024-12-24T05:12:25.259205Z","iopub.status.idle":"2024-12-24T05:12:26.269400Z","shell.execute_reply.started":"2024-12-24T05:12:25.259183Z","shell.execute_reply":"2024-12-24T05:12:26.268701Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"from tqdm import tqdm\nimport numpy as np\n\ndef safe_encode_text(x, vocab, min_len=512):\n    try:\n        encoded = encode_text(x, vocab, min_len)\n        # Normalize indices by dividing by vocabulary size\n        normalized = np.array(encoded, dtype=np.float32) / len(vocab)\n        return normalized\n    except Exception as e:\n        print(f\"Error encoding text: {str(e)[:100]}\")\n        return np.zeros(min_len, dtype=np.float32)\n\n# Using tqdm for progress tracking\ntqdm.pandas()\ndf_train['txt_ids'] = df_train['text'].progress_map(lambda x: safe_encode_text(x, vocab))\n\n# Convert the entire column to a list of numpy arrays if needed\ndf_train['txt_ids'] = df_train['txt_ids'].apply(lambda x: np.array(x, dtype=np.float32) if isinstance(x, str) else x)\n\n# Verify the data type and values\nprint(\"Type of first element:\", type(df_train['txt_ids'].iloc[0]))\nprint(\"Shape of first element:\", df_train['txt_ids'].iloc[0].shape)\nprint(\"Data type of first element:\", df_train['txt_ids'].iloc[0].dtype)\nprint(\"Min value:\", df_train['txt_ids'].iloc[0].min())\nprint(\"Max value:\", df_train['txt_ids'].iloc[0].max())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T05:17:22.478479Z","iopub.execute_input":"2024-12-24T05:17:22.478838Z","iopub.status.idle":"2024-12-24T05:27:05.867306Z","shell.execute_reply.started":"2024-12-24T05:17:22.478806Z","shell.execute_reply":"2024-12-24T05:27:05.866387Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 40000/40000 [09:43<00:00, 68.57it/s] \n","output_type":"stream"},{"name":"stdout","text":"Type of first element: <class 'numpy.ndarray'>\nShape of first element: (512,)\nData type of first element: float64\nMin value: 0.0\nMax value: 0.0010111350461919147\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"df_train.to_csv('df_train_encoded.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T05:27:22.020976Z","iopub.execute_input":"2024-12-24T05:27:22.021370Z","iopub.status.idle":"2024-12-24T05:29:17.561931Z","shell.execute_reply.started":"2024-12-24T05:27:22.021342Z","shell.execute_reply":"2024-12-24T05:29:17.560930Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T05:30:11.749605Z","iopub.execute_input":"2024-12-24T05:30:11.749921Z","iopub.status.idle":"2024-12-24T05:30:11.763741Z","shell.execute_reply.started":"2024-12-24T05:30:11.749896Z","shell.execute_reply":"2024-12-24T05:30:11.762793Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"                                                text  label  \\\n0  If you havent seen this movie than you need to...      1   \n1  but Cinderella gets my vote not only for the w...      0   \n2  This movie is pretty cheesy but I do give it c...      1   \n3  I have not seen a Van Damme flick for a while ...      1   \n4  This is a sleeper It defines Nicholas Cage The...      1   \n\n                                             txt_ids  \n0  [0.0, 6.280341901813135e-06, 1.256068380362627...  \n1  [0.0010174153880937278, 0.001023695729995541, ...  \n2  [2.512136760725254e-05, 3.1401709509065676e-05...  \n3  [0.00023237265036708598, 8.792478662538388e-05...  \n4  [2.512136760725254e-05, 0.00011932649613444957...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>txt_ids</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>If you havent seen this movie than you need to...</td>\n      <td>1</td>\n      <td>[0.0, 6.280341901813135e-06, 1.256068380362627...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>but Cinderella gets my vote not only for the w...</td>\n      <td>0</td>\n      <td>[0.0010174153880937278, 0.001023695729995541, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>This movie is pretty cheesy but I do give it c...</td>\n      <td>1</td>\n      <td>[2.512136760725254e-05, 3.1401709509065676e-05...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I have not seen a Van Damme flick for a while ...</td>\n      <td>1</td>\n      <td>[0.00023237265036708598, 8.792478662538388e-05...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>This is a sleeper It defines Nicholas Cage The...</td>\n      <td>1</td>\n      <td>[2.512136760725254e-05, 0.00011932649613444957...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"import numpy as np\n\nX = np.stack(df_train['txt_ids'].values)\nprint(X.shape)\ny = df_final['label'].values\nprint(y.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T05:30:57.978843Z","iopub.execute_input":"2024-12-24T05:30:57.979215Z","iopub.status.idle":"2024-12-24T05:30:58.061743Z","shell.execute_reply.started":"2024-12-24T05:30:57.979184Z","shell.execute_reply":"2024-12-24T05:30:58.060932Z"}},"outputs":[{"name":"stdout","text":"(40000, 512)\n(40000,)\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"df_final['label'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T05:31:06.098206Z","iopub.execute_input":"2024-12-24T05:31:06.098489Z","iopub.status.idle":"2024-12-24T05:31:06.105214Z","shell.execute_reply.started":"2024-12-24T05:31:06.098466Z","shell.execute_reply":"2024-12-24T05:31:06.104462Z"}},"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"label\n0    20049\n1    19951\nName: count, dtype: int64"},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"import tensorflow as tf\nimport keras\nfrom sklearn.model_selection import train_test_split\n\n# 1. Dataset Creation\ndef create_tf_dataset(X, y, batch_size=32):\n    \"\"\"Create TensorFlow dataset\"\"\"\n    return tf.data.Dataset.from_tensor_slices(\n        (tf.cast(X, tf.float32), tf.cast(y, tf.float32))\n    ).shuffle(1000).batch(batch_size)\n\n# 2. Learning Rate Callback\nclass PrintLearningRate(keras.callbacks.Callback):\n    \"\"\"Callback to print learning rate\"\"\"\n    def on_batch_end(self, batch, logs=None):\n        lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n        logs['lr'] = lr\n\n# 3. Callbacks Creation\ndef create_callbacks(params):\n    \"\"\"Create training callbacks\"\"\"\n    return [\n        keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=params['early_stopping_patience'],\n            restore_best_weights=True,\n            verbose=0\n        ),\n        keras.callbacks.ReduceLROnPlateau(\n            monitor='val_loss',\n            factor=params['reduce_lr_factor'],\n            patience=params['reduce_lr_patience'],\n            min_lr=1e-6,\n            verbose=0\n        ),\n        keras.callbacks.ModelCheckpoint(\n            'best_model.keras',\n            monitor='val_loss',\n            save_best_only=True,\n            verbose=0\n        ),\n        PrintLearningRate()\n    ]\n\n# 4. Model Creation\ndef create_model(input_shape, params, dense_only=False):\n    \"\"\"Create the model architecture\"\"\"\n    input_layer = keras.layers.Input(shape=input_shape)\n    x = input_layer\n    \n    if not dense_only:\n        # GRU layers\n        x = keras.layers.Reshape((1, -1))(x)\n        \n        for units in params['gru_units']:\n            x = keras.layers.GRU(\n                units, \n                return_sequences=True if units != params['gru_units'][-1] else False,\n                dropout=params['dropout_rate'],\n                recurrent_dropout=params['dropout_rate']\n            )(x)\n            x = keras.layers.BatchNormalization()(x)\n            x = keras.layers.Dropout(params['dropout_rate'])(x)\n    \n    # Dense layers\n    units = params['dense_units']\n    for _ in range(3):\n        if units < 5:\n            units = 5\n        x = keras.layers.Dense(\n            units,\n            activation=keras.activations.gelu,\n            kernel_initializer=keras.initializers.he_normal,\n            kernel_regularizer=keras.regularizers.l1_l2(params['l1_l2_reg']),\n        )(x)\n        x = keras.layers.BatchNormalization()(x)\n        x = keras.layers.Dropout(rate=params['dropout_rate'])(x)\n        units //= 2\n\n    output_layer = keras.layers.Dense(1, activation=keras.activations.sigmoid)(x)\n    \n    model = keras.Model(inputs=input_layer, outputs=output_layer)\n    model.compile(\n        optimizer=keras.optimizers.Adam(\n            learning_rate=params['initial_lr'],\n            clipnorm=1.0\n        ),\n        loss=keras.losses.binary_crossentropy,\n        metrics=[keras.metrics.binary_accuracy]\n    )\n    \n    return model\n\n# 5. Main Training Function\ndef setup_and_train(X, y, \n                    resume_training=False,\n                    dense_only=False,\n                    model_path='best_model.keras',\n                    gru_units=[1000, 750, 550],\n                    dense_units=520,\n                    dropout_rate=0.2,\n                    initial_lr=1e-3,\n                    early_stopping_patience=3,\n                    reduce_lr_patience=2,\n                    reduce_lr_factor=0.2,\n                    epochs=200,\n                    batch_size=512*2,\n                    l1_l2_reg=0.01):\n    \"\"\"\n    Main function to setup and train the model\n    Args:\n        resume_training: If True, loads previous model and continues training\n        dense_only: If True, uses only dense layers without GRU\n        reduce_lr_factor: Factor by which learning rate is reduced (default 0.2)\n        Other args: Model hyperparameters\n    \"\"\"\n    \n    # Create parameter dictionary\n    params = {\n        'gru_units': gru_units,\n        'dense_units': dense_units,\n        'dropout_rate': dropout_rate,\n        'initial_lr': initial_lr,\n        'early_stopping_patience': early_stopping_patience,\n        'reduce_lr_patience': reduce_lr_patience,\n        'reduce_lr_factor': reduce_lr_factor,\n        'epochs': epochs,\n        'batch_size': batch_size,\n        'l1_l2_reg': l1_l2_reg\n    }\n    \n    # Split data\n    X_full, X_test, y_full, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n    X_train, X_val, y_train, y_val = train_test_split(X_full, y_full, test_size=0.3, random_state=0)\n    \n    # Setup strategy\n    strategy = tf.distribute.MirroredStrategy()\n    print(f'Number of devices: {strategy.num_replicas_in_sync}')\n    print(f\"Data shapes: {X_train.shape}, {X_val.shape}, {X_test.shape}\\n\")\n    \n    # Create or load model\n    with strategy.scope():\n        if resume_training:\n            try:\n                model = keras.models.load_model(model_path)\n                print(\"Resuming training from saved model\")\n                keras.backend.set_value(model.optimizer.learning_rate, initial_lr)\n            except:\n                print(f\"No saved model found at {model_path}. Creating new model.\")\n                model = create_model((X_train.shape[1],), params, dense_only)\n        else:\n            print(\"Creating new model\")\n            model = create_model((X_train.shape[1],), params, dense_only)\n    \n    # Create datasets\n    train_dataset = create_tf_dataset(X_train, y_train, params['batch_size'])\n    val_dataset = create_tf_dataset(X_val, y_val, params['batch_size'])\n    test_dataset = create_tf_dataset(X_test, y_test, 128)\n    \n    # Train model\n    history = model.fit(\n        train_dataset,\n        epochs=params['epochs'],\n        validation_data=val_dataset,\n        callbacks=create_callbacks(params),\n        verbose=1\n    )\n    \n    # Evaluate model\n    test_results = model.evaluate(test_dataset, verbose=0)\n    print(f\"\\nTest Loss: {test_results[0]:.4f}\")\n    print(f\"Test Accuracy: {test_results[1]:.4f}\")\n    \n    return model, history, params\n\n\nprint('done')\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T06:40:34.436665Z","iopub.execute_input":"2024-12-24T06:40:34.436991Z","iopub.status.idle":"2024-12-24T06:40:34.453933Z","shell.execute_reply.started":"2024-12-24T06:40:34.436962Z","shell.execute_reply":"2024-12-24T06:40:34.453087Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"done\n","output_type":"stream"}],"execution_count":71},{"cell_type":"code","source":"# 1. Create new model\nmodel, history, params = setup_and_train(X, y, \n                    resume_training=False,\n                    dense_only=False,\n                    model_path='best_dense_only_model.keras',\n                    gru_units=[1000, 750, 550],\n                    dense_units=300,\n                    dropout_rate=0.2,\n                    initial_lr=0.1,\n                    early_stopping_patience=20,\n                    reduce_lr_patience=5,\n                    reduce_lr_factor=0.5,\n                    epochs=200,\n                    batch_size=512*2,\n                    l1_l2_reg=0.1)\n\n\"\"\"\"\n# 2. Resume training\nmodel, history, params = setup_and_train(\n    X, y,\n    resume_training=True,\n    initial_lr=5e-4,\n    epochs=100,\n    batch_size=1024\n)\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T06:38:23.322517Z","iopub.execute_input":"2024-12-24T06:38:23.322818Z","iopub.status.idle":"2024-12-24T06:40:20.283260Z","shell.execute_reply.started":"2024-12-24T06:38:23.322795Z","shell.execute_reply":"2024-12-24T06:40:20.282090Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"Number of devices: 2\nData shapes: (22400, 512), (9600, 512), (8000, 512)\n\nCreating new model\nEpoch 1/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 59ms/step - binary_accuracy: 0.5017 - loss: 818.9078 - lr: 0.1000 - val_binary_accuracy: 0.4944 - val_loss: 409.0956 - learning_rate: 0.1000\nEpoch 2/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - binary_accuracy: 0.4964 - loss: 330.0677 - lr: 0.1000 - val_binary_accuracy: 0.4942 - val_loss: 258.3411 - learning_rate: 0.1000\nEpoch 3/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.5001 - loss: 267.9983 - lr: 0.1000 - val_binary_accuracy: 0.4996 - val_loss: 267.1272 - learning_rate: 0.1000\nEpoch 4/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - binary_accuracy: 0.5066 - loss: 259.9080 - lr: 0.1000 - val_binary_accuracy: 0.5006 - val_loss: 274.4033 - learning_rate: 0.1000\nEpoch 5/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - binary_accuracy: 0.5010 - loss: 261.7596 - lr: 0.1000 - val_binary_accuracy: 0.4944 - val_loss: 251.1309 - learning_rate: 0.1000\nEpoch 6/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - binary_accuracy: 0.5025 - loss: 254.4379 - lr: 0.1000 - val_binary_accuracy: 0.4950 - val_loss: 248.5272 - learning_rate: 0.1000\nEpoch 7/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - binary_accuracy: 0.5003 - loss: 251.5164 - lr: 0.1000 - val_binary_accuracy: 0.5085 - val_loss: 273.5090 - learning_rate: 0.1000\nEpoch 8/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - binary_accuracy: 0.5000 - loss: 254.8603 - lr: 0.1000 - val_binary_accuracy: 0.5031 - val_loss: 241.9129 - learning_rate: 0.1000\nEpoch 9/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.4953 - loss: 251.9011 - lr: 0.1000 - val_binary_accuracy: 0.5031 - val_loss: 256.0013 - learning_rate: 0.1000\nEpoch 10/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.4918 - loss: 249.2657 - lr: 0.1000 - val_binary_accuracy: 0.5096 - val_loss: 265.8148 - learning_rate: 0.1000\nEpoch 11/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - binary_accuracy: 0.4943 - loss: 252.7162 - lr: 0.1000 - val_binary_accuracy: 0.5004 - val_loss: 246.5804 - learning_rate: 0.1000\nEpoch 12/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.4998 - loss: 249.0909 - lr: 0.1000 - val_binary_accuracy: 0.5029 - val_loss: 244.6045 - learning_rate: 0.1000\nEpoch 13/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.5011 - loss: 247.8692 - lr: 0.1000 - val_binary_accuracy: 0.4900 - val_loss: 265.5399 - learning_rate: 0.1000\nEpoch 14/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - binary_accuracy: 0.5068 - loss: 194.4303 - lr: 0.0500 - val_binary_accuracy: 0.5015 - val_loss: 128.4521 - learning_rate: 0.0500\nEpoch 15/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - binary_accuracy: 0.5005 - loss: 135.4387 - lr: 0.0500 - val_binary_accuracy: 0.5077 - val_loss: 123.6870 - learning_rate: 0.0500\nEpoch 16/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - binary_accuracy: 0.4949 - loss: 123.9224 - lr: 0.0500 - val_binary_accuracy: 0.4994 - val_loss: 129.7084 - learning_rate: 0.0500\nEpoch 17/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.5003 - loss: 123.2851 - lr: 0.0500 - val_binary_accuracy: 0.4990 - val_loss: 124.2010 - learning_rate: 0.0500\nEpoch 18/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - binary_accuracy: 0.5049 - loss: 124.1967 - lr: 0.0500 - val_binary_accuracy: 0.5025 - val_loss: 121.1401 - learning_rate: 0.0500\nEpoch 19/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - binary_accuracy: 0.4916 - loss: 122.5580 - lr: 0.0500 - val_binary_accuracy: 0.4963 - val_loss: 123.9223 - learning_rate: 0.0500\nEpoch 20/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - binary_accuracy: 0.4963 - loss: 121.6508 - lr: 0.0500 - val_binary_accuracy: 0.5044 - val_loss: 119.7026 - learning_rate: 0.0500\nEpoch 21/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.4943 - loss: 120.9353 - lr: 0.0500 - val_binary_accuracy: 0.4971 - val_loss: 124.5650 - learning_rate: 0.0500\nEpoch 22/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.4977 - loss: 121.1051 - lr: 0.0500 - val_binary_accuracy: 0.5121 - val_loss: 128.6371 - learning_rate: 0.0500\nEpoch 23/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - binary_accuracy: 0.4954 - loss: 122.3344 - lr: 0.0500 - val_binary_accuracy: 0.4975 - val_loss: 119.0981 - learning_rate: 0.0500\nEpoch 24/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.4998 - loss: 120.3094 - lr: 0.0500 - val_binary_accuracy: 0.4956 - val_loss: 120.2642 - learning_rate: 0.0500\nEpoch 25/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - binary_accuracy: 0.4976 - loss: 120.0904 - lr: 0.0500 - val_binary_accuracy: 0.5008 - val_loss: 127.3848 - learning_rate: 0.0500\nEpoch 26/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - binary_accuracy: 0.4937 - loss: 121.5487 - lr: 0.0500 - val_binary_accuracy: 0.4998 - val_loss: 120.1697 - learning_rate: 0.0500\nEpoch 27/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - binary_accuracy: 0.4996 - loss: 120.6329 - lr: 0.0500 - val_binary_accuracy: 0.5050 - val_loss: 119.6980 - learning_rate: 0.0500\nEpoch 28/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - binary_accuracy: 0.4988 - loss: 119.5588 - lr: 0.0500 - val_binary_accuracy: 0.5002 - val_loss: 124.3599 - learning_rate: 0.0500\nEpoch 29/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - binary_accuracy: 0.4951 - loss: 94.4375 - lr: 0.0250 - val_binary_accuracy: 0.5069 - val_loss: 63.9524 - learning_rate: 0.0250\nEpoch 30/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - binary_accuracy: 0.5006 - loss: 67.1368 - lr: 0.0250 - val_binary_accuracy: 0.4985 - val_loss: 62.9179 - learning_rate: 0.0250\nEpoch 31/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - binary_accuracy: 0.4982 - loss: 62.2422 - lr: 0.0250 - val_binary_accuracy: 0.5021 - val_loss: 65.0067 - learning_rate: 0.0250\nEpoch 32/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - binary_accuracy: 0.4989 - loss: 61.6355 - lr: 0.0250 - val_binary_accuracy: 0.4904 - val_loss: 60.6838 - learning_rate: 0.0250\nEpoch 33/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - binary_accuracy: 0.5011 - loss: 61.6590 - lr: 0.0250 - val_binary_accuracy: 0.5033 - val_loss: 61.8234 - learning_rate: 0.0250\nEpoch 34/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.5017 - loss: 61.1328 - lr: 0.0250 - val_binary_accuracy: 0.4890 - val_loss: 61.2372 - learning_rate: 0.0250\nEpoch 35/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.4992 - loss: 61.2364 - lr: 0.0250 - val_binary_accuracy: 0.4958 - val_loss: 61.4410 - learning_rate: 0.0250\nEpoch 36/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - binary_accuracy: 0.4977 - loss: 61.0098 - lr: 0.0250 - val_binary_accuracy: 0.5023 - val_loss: 62.9263 - learning_rate: 0.0250\nEpoch 37/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - binary_accuracy: 0.4952 - loss: 61.0106 - lr: 0.0250 - val_binary_accuracy: 0.4938 - val_loss: 63.8867 - learning_rate: 0.0250\nEpoch 38/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - binary_accuracy: 0.5013 - loss: 47.6153 - lr: 0.0125 - val_binary_accuracy: 0.4985 - val_loss: 32.2201 - learning_rate: 0.0125\nEpoch 39/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - binary_accuracy: 0.5041 - loss: 34.3218 - lr: 0.0125 - val_binary_accuracy: 0.5052 - val_loss: 32.4882 - learning_rate: 0.0125\nEpoch 40/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.5017 - loss: 31.9315 - lr: 0.0125 - val_binary_accuracy: 0.5075 - val_loss: 33.6303 - learning_rate: 0.0125\nEpoch 41/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - binary_accuracy: 0.4993 - loss: 31.4672 - lr: 0.0125 - val_binary_accuracy: 0.4981 - val_loss: 29.9087 - learning_rate: 0.0125\nEpoch 42/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.4986 - loss: 31.3814 - lr: 0.0125 - val_binary_accuracy: 0.5002 - val_loss: 31.6975 - learning_rate: 0.0125\nEpoch 43/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.4946 - loss: 31.4599 - lr: 0.0125 - val_binary_accuracy: 0.4994 - val_loss: 31.0551 - learning_rate: 0.0125\nEpoch 44/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - binary_accuracy: 0.5031 - loss: 31.6489 - lr: 0.0125 - val_binary_accuracy: 0.4996 - val_loss: 31.5180 - learning_rate: 0.0125\nEpoch 45/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.4990 - loss: 31.4304 - lr: 0.0125 - val_binary_accuracy: 0.5035 - val_loss: 32.4860 - learning_rate: 0.0125\nEpoch 46/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.4971 - loss: 31.2905 - lr: 0.0125 - val_binary_accuracy: 0.4938 - val_loss: 32.6842 - learning_rate: 0.0125\nEpoch 47/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - binary_accuracy: 0.5005 - loss: 24.3516 - lr: 0.0063 - val_binary_accuracy: 0.5098 - val_loss: 16.8326 - learning_rate: 0.0063\nEpoch 48/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - binary_accuracy: 0.4982 - loss: 17.5928 - lr: 0.0063 - val_binary_accuracy: 0.5015 - val_loss: 16.5303 - learning_rate: 0.0063\nEpoch 49/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - binary_accuracy: 0.5033 - loss: 16.3232 - lr: 0.0063 - val_binary_accuracy: 0.4988 - val_loss: 17.2036 - learning_rate: 0.0063\nEpoch 50/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - binary_accuracy: 0.5029 - loss: 16.0658 - lr: 0.0063 - val_binary_accuracy: 0.5094 - val_loss: 15.2352 - learning_rate: 0.0063\nEpoch 51/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.5016 - loss: 16.0280 - lr: 0.0063 - val_binary_accuracy: 0.4992 - val_loss: 16.1605 - learning_rate: 0.0063\nEpoch 52/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.5036 - loss: 16.1625 - lr: 0.0063 - val_binary_accuracy: 0.4990 - val_loss: 16.0175 - learning_rate: 0.0063\nEpoch 53/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - binary_accuracy: 0.5042 - loss: 16.2921 - lr: 0.0063 - val_binary_accuracy: 0.4988 - val_loss: 16.1570 - learning_rate: 0.0063\nEpoch 54/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.5032 - loss: 16.1173 - lr: 0.0063 - val_binary_accuracy: 0.5027 - val_loss: 16.5428 - learning_rate: 0.0063\nEpoch 55/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.5003 - loss: 15.9959 - lr: 0.0063 - val_binary_accuracy: 0.5004 - val_loss: 16.5278 - learning_rate: 0.0063\nEpoch 56/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - binary_accuracy: 0.5001 - loss: 12.3889 - lr: 0.0031 - val_binary_accuracy: 0.5023 - val_loss: 8.8592 - learning_rate: 0.0031\nEpoch 57/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - binary_accuracy: 0.4995 - loss: 9.0707 - lr: 0.0031 - val_binary_accuracy: 0.5125 - val_loss: 8.4266 - learning_rate: 0.0031\nEpoch 58/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.5031 - loss: 8.4119 - lr: 0.0031 - val_binary_accuracy: 0.4960 - val_loss: 8.8257 - learning_rate: 0.0031\nEpoch 59/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - binary_accuracy: 0.5029 - loss: 8.2877 - lr: 0.0031 - val_binary_accuracy: 0.4919 - val_loss: 7.9496 - learning_rate: 0.0031\nEpoch 60/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - binary_accuracy: 0.5039 - loss: 8.2755 - lr: 0.0031 - val_binary_accuracy: 0.5054 - val_loss: 8.3266 - learning_rate: 0.0031\nEpoch 61/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - binary_accuracy: 0.5024 - loss: 8.3686 - lr: 0.0031 - val_binary_accuracy: 0.5069 - val_loss: 8.3811 - learning_rate: 0.0031\nEpoch 62/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - binary_accuracy: 0.5030 - loss: 8.4261 - lr: 0.0031 - val_binary_accuracy: 0.5042 - val_loss: 8.2809 - learning_rate: 0.0031\nEpoch 63/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.5036 - loss: 8.3137 - lr: 0.0031 - val_binary_accuracy: 0.5033 - val_loss: 8.4750 - learning_rate: 0.0031\nEpoch 64/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.5035 - loss: 8.2472 - lr: 0.0031 - val_binary_accuracy: 0.4990 - val_loss: 8.5979 - learning_rate: 0.0031\nEpoch 65/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - binary_accuracy: 0.5039 - loss: 6.5156 - lr: 0.0016 - val_binary_accuracy: 0.5033 - val_loss: 4.7871 - learning_rate: 0.0016\nEpoch 66/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - binary_accuracy: 0.5033 - loss: 4.8686 - lr: 0.0016 - val_binary_accuracy: 0.4965 - val_loss: 4.5342 - learning_rate: 0.0016\nEpoch 67/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - binary_accuracy: 0.5042 - loss: 4.5303 - lr: 0.0016 - val_binary_accuracy: 0.4948 - val_loss: 4.7188 - learning_rate: 0.0016\nEpoch 68/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - binary_accuracy: 0.4979 - loss: 4.4604 - lr: 0.0016 - val_binary_accuracy: 0.5008 - val_loss: 4.3184 - learning_rate: 0.0016\nEpoch 69/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.5023 - loss: 4.4569 - lr: 0.0016 - val_binary_accuracy: 0.5027 - val_loss: 4.5060 - learning_rate: 0.0016\nEpoch 70/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - binary_accuracy: 0.5025 - loss: 4.5080 - lr: 0.0016 - val_binary_accuracy: 0.5006 - val_loss: 4.5048 - learning_rate: 0.0016\nEpoch 71/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.4978 - loss: 4.5401 - lr: 0.0016 - val_binary_accuracy: 0.4971 - val_loss: 4.4553 - learning_rate: 0.0016\nEpoch 72/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - binary_accuracy: 0.5040 - loss: 4.4794 - lr: 0.0016 - val_binary_accuracy: 0.5040 - val_loss: 4.5201 - learning_rate: 0.0016\nEpoch 73/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - binary_accuracy: 0.5039 - loss: 4.4367 - lr: 0.0016 - val_binary_accuracy: 0.4963 - val_loss: 4.6254 - learning_rate: 0.0016\nEpoch 74/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - binary_accuracy: 0.5029 - loss: 3.5958 - lr: 7.8125e-04 - val_binary_accuracy: 0.5017 - val_loss: 2.7647 - learning_rate: 7.8125e-04\nEpoch 75/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - binary_accuracy: 0.5036 - loss: 2.7815 - lr: 7.8125e-04 - val_binary_accuracy: 0.4915 - val_loss: 2.6041 - learning_rate: 7.8125e-04\nEpoch 76/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.5026 - loss: 2.6073 - lr: 7.8125e-04 - val_binary_accuracy: 0.4904 - val_loss: 2.6979 - learning_rate: 7.8125e-04\nEpoch 77/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - binary_accuracy: 0.5041 - loss: 2.5738 - lr: 7.8125e-04 - val_binary_accuracy: 0.4958 - val_loss: 2.4985 - learning_rate: 7.8125e-04\nEpoch 78/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.5045 - loss: 2.5695 - lr: 7.8125e-04 - val_binary_accuracy: 0.4996 - val_loss: 2.5923 - learning_rate: 7.8125e-04\nEpoch 79/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.5030 - loss: 2.5985 - lr: 7.8125e-04 - val_binary_accuracy: 0.4890 - val_loss: 2.6005 - learning_rate: 7.8125e-04\nEpoch 80/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.5032 - loss: 2.6138 - lr: 7.8125e-04 - val_binary_accuracy: 0.4971 - val_loss: 2.5778 - learning_rate: 7.8125e-04\nEpoch 81/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - binary_accuracy: 0.5037 - loss: 2.5837 - lr: 7.8125e-04 - val_binary_accuracy: 0.4996 - val_loss: 2.5866 - learning_rate: 7.8125e-04\nEpoch 82/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.5030 - loss: 2.5598 - lr: 7.8125e-04 - val_binary_accuracy: 0.4956 - val_loss: 2.6482 - learning_rate: 7.8125e-04\nEpoch 83/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - binary_accuracy: 0.5040 - loss: 2.1429 - lr: 3.9063e-04 - val_binary_accuracy: 0.4871 - val_loss: 1.7359 - learning_rate: 3.9063e-04\nEpoch 84/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - binary_accuracy: 0.5035 - loss: 1.7367 - lr: 3.9063e-04 - val_binary_accuracy: 0.5008 - val_loss: 1.6470 - learning_rate: 3.9063e-04\nEpoch 85/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - binary_accuracy: 0.5049 - loss: 1.6491 - lr: 3.9063e-04 - val_binary_accuracy: 0.4967 - val_loss: 1.6927 - learning_rate: 3.9063e-04\nEpoch 86/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - binary_accuracy: 0.5026 - loss: 1.6312 - lr: 3.9063e-04 - val_binary_accuracy: 0.4867 - val_loss: 1.5928 - learning_rate: 3.9063e-04\nEpoch 87/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.5046 - loss: 1.6303 - lr: 3.9063e-04 - val_binary_accuracy: 0.5038 - val_loss: 1.6378 - learning_rate: 3.9063e-04\nEpoch 88/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - binary_accuracy: 0.5031 - loss: 1.6426 - lr: 3.9063e-04 - val_binary_accuracy: 0.5019 - val_loss: 1.6526 - learning_rate: 3.9063e-04\nEpoch 89/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.5029 - loss: 1.6520 - lr: 3.9063e-04 - val_binary_accuracy: 0.5021 - val_loss: 1.6355 - learning_rate: 3.9063e-04\nEpoch 90/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - binary_accuracy: 0.5017 - loss: 1.6371 - lr: 3.9063e-04 - val_binary_accuracy: 0.4963 - val_loss: 1.6306 - learning_rate: 3.9063e-04\nEpoch 91/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - binary_accuracy: 0.5023 - loss: 1.6249 - lr: 3.9063e-04 - val_binary_accuracy: 0.5040 - val_loss: 1.6656 - learning_rate: 3.9063e-04\nEpoch 92/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - binary_accuracy: 0.5019 - loss: 1.4153 - lr: 1.9531e-04 - val_binary_accuracy: 0.5021 - val_loss: 1.2149 - learning_rate: 1.9531e-04\nEpoch 93/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - binary_accuracy: 0.5036 - loss: 1.2144 - lr: 1.9531e-04 - val_binary_accuracy: 0.4967 - val_loss: 1.1676 - learning_rate: 1.9531e-04\nEpoch 94/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - binary_accuracy: 0.5030 - loss: 1.1706 - lr: 1.9531e-04 - val_binary_accuracy: 0.4985 - val_loss: 1.1878 - learning_rate: 1.9531e-04\nEpoch 95/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - binary_accuracy: 0.5025 - loss: 1.1609 - lr: 1.9531e-04 - val_binary_accuracy: 0.5071 - val_loss: 1.1413 - learning_rate: 1.9531e-04\nEpoch 96/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - binary_accuracy: 0.5037 - loss: 1.1609 - lr: 1.9531e-04 - val_binary_accuracy: 0.5035 - val_loss: 1.1664 - learning_rate: 1.9531e-04\nEpoch 97/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - binary_accuracy: 0.5033 - loss: 1.1676 - lr: 1.9531e-04 - val_binary_accuracy: 0.5023 - val_loss: 1.1710 - learning_rate: 1.9531e-04\nEpoch 98/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.5023 - loss: 1.1719 - lr: 1.9531e-04 - val_binary_accuracy: 0.5000 - val_loss: 1.1630 - learning_rate: 1.9531e-04\nEpoch 99/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.5027 - loss: 1.1640 - lr: 1.9531e-04 - val_binary_accuracy: 0.5013 - val_loss: 1.1589 - learning_rate: 1.9531e-04\nEpoch 100/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - binary_accuracy: 0.5038 - loss: 1.1579 - lr: 1.9531e-04 - val_binary_accuracy: 0.4875 - val_loss: 1.1781 - learning_rate: 1.9531e-04\nEpoch 101/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - binary_accuracy: 0.5034 - loss: 1.0534 - lr: 9.7656e-05 - val_binary_accuracy: 0.5044 - val_loss: 0.9542 - learning_rate: 9.7656e-05\nEpoch 102/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - binary_accuracy: 0.5045 - loss: 0.9537 - lr: 9.7656e-05 - val_binary_accuracy: 0.4867 - val_loss: 0.9313 - learning_rate: 9.7656e-05\nEpoch 103/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.5036 - loss: 0.9320 - lr: 9.7656e-05 - val_binary_accuracy: 0.5033 - val_loss: 0.9408 - learning_rate: 9.7656e-05\nEpoch 104/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - binary_accuracy: 0.5025 - loss: 0.9274 - lr: 9.7656e-05 - val_binary_accuracy: 0.5079 - val_loss: 0.9161 - learning_rate: 9.7656e-05\nEpoch 105/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.5047 - loss: 0.9272 - lr: 9.7656e-05 - val_binary_accuracy: 0.5031 - val_loss: 0.9292 - learning_rate: 9.7656e-05\nEpoch 106/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.5041 - loss: 0.9303 - lr: 9.7656e-05 - val_binary_accuracy: 0.4996 - val_loss: 0.9314 - learning_rate: 9.7656e-05\nEpoch 107/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - binary_accuracy: 0.5015 - loss: 0.9326 - lr: 9.7656e-05 - val_binary_accuracy: 0.5029 - val_loss: 0.9284 - learning_rate: 9.7656e-05\nEpoch 108/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - binary_accuracy: 0.5040 - loss: 0.9291 - lr: 9.7656e-05 - val_binary_accuracy: 0.4948 - val_loss: 0.9250 - learning_rate: 9.7656e-05\nEpoch 109/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - binary_accuracy: 0.5030 - loss: 0.9257 - lr: 9.7656e-05 - val_binary_accuracy: 0.4996 - val_loss: 0.9344 - learning_rate: 9.7656e-05\nEpoch 110/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - binary_accuracy: 0.5026 - loss: 0.8729 - lr: 4.8828e-05 - val_binary_accuracy: 0.5063 - val_loss: 0.8234 - learning_rate: 4.8828e-05\nEpoch 111/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - binary_accuracy: 0.5034 - loss: 0.8232 - lr: 4.8828e-05 - val_binary_accuracy: 0.5044 - val_loss: 0.8123 - learning_rate: 4.8828e-05\nEpoch 112/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.5030 - loss: 0.8125 - lr: 4.8828e-05 - val_binary_accuracy: 0.4969 - val_loss: 0.8163 - learning_rate: 4.8828e-05\nEpoch 113/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - binary_accuracy: 0.5039 - loss: 0.8101 - lr: 4.8828e-05 - val_binary_accuracy: 0.5002 - val_loss: 0.8049 - learning_rate: 4.8828e-05\nEpoch 114/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.5024 - loss: 0.8102 - lr: 4.8828e-05 - val_binary_accuracy: 0.5090 - val_loss: 0.8110 - learning_rate: 4.8828e-05\nEpoch 115/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - binary_accuracy: 0.5030 - loss: 0.8117 - lr: 4.8828e-05 - val_binary_accuracy: 0.4902 - val_loss: 0.8126 - learning_rate: 4.8828e-05\nEpoch 116/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.5025 - loss: 0.8128 - lr: 4.8828e-05 - val_binary_accuracy: 0.4967 - val_loss: 0.8105 - learning_rate: 4.8828e-05\nEpoch 117/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.5033 - loss: 0.8110 - lr: 4.8828e-05 - val_binary_accuracy: 0.4952 - val_loss: 0.8091 - learning_rate: 4.8828e-05\nEpoch 118/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.5034 - loss: 0.8095 - lr: 4.8828e-05 - val_binary_accuracy: 0.5017 - val_loss: 0.8130 - learning_rate: 4.8828e-05\nEpoch 119/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - binary_accuracy: 0.5035 - loss: 0.7828 - lr: 2.4414e-05 - val_binary_accuracy: 0.4998 - val_loss: 0.7585 - learning_rate: 2.4414e-05\nEpoch 120/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - binary_accuracy: 0.5043 - loss: 0.7581 - lr: 2.4414e-05 - val_binary_accuracy: 0.5006 - val_loss: 0.7527 - learning_rate: 2.4414e-05\nEpoch 121/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - binary_accuracy: 0.5036 - loss: 0.7527 - lr: 2.4414e-05 - val_binary_accuracy: 0.4925 - val_loss: 0.7549 - learning_rate: 2.4414e-05\nEpoch 122/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - binary_accuracy: 0.5049 - loss: 0.7516 - lr: 2.4414e-05 - val_binary_accuracy: 0.4992 - val_loss: 0.7490 - learning_rate: 2.4414e-05\nEpoch 123/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - binary_accuracy: 0.5023 - loss: 0.7516 - lr: 2.4414e-05 - val_binary_accuracy: 0.4994 - val_loss: 0.7524 - learning_rate: 2.4414e-05\nEpoch 124/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - binary_accuracy: 0.5037 - loss: 0.7523 - lr: 2.4414e-05 - val_binary_accuracy: 0.4988 - val_loss: 0.7528 - learning_rate: 2.4414e-05\nEpoch 125/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - binary_accuracy: 0.5036 - loss: 0.7529 - lr: 2.4414e-05 - val_binary_accuracy: 0.5075 - val_loss: 0.7518 - learning_rate: 2.4414e-05\nEpoch 126/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - binary_accuracy: 0.5037 - loss: 0.7520 - lr: 2.4414e-05 - val_binary_accuracy: 0.4958 - val_loss: 0.7511 - learning_rate: 2.4414e-05\nEpoch 127/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - binary_accuracy: 0.5039 - loss: 0.7512 - lr: 2.4414e-05 - val_binary_accuracy: 0.4952 - val_loss: 0.7532 - learning_rate: 2.4414e-05\nEpoch 128/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.5043 - loss: 0.7380 - lr: 1.2207e-05 - val_binary_accuracy: 0.4869 - val_loss: 0.7261 - learning_rate: 1.2207e-05\nEpoch 129/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - binary_accuracy: 0.5040 - loss: 0.7256 - lr: 1.2207e-05 - val_binary_accuracy: 0.5073 - val_loss: 0.7230 - learning_rate: 1.2207e-05\nEpoch 130/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - binary_accuracy: 0.5044 - loss: 0.7230 - lr: 1.2207e-05 - val_binary_accuracy: 0.5042 - val_loss: 0.7240 - learning_rate: 1.2207e-05\nEpoch 131/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.5046 - loss: 0.7224 - lr: 1.2207e-05 - val_binary_accuracy: 0.4985 - val_loss: 0.7211 - learning_rate: 1.2207e-05\nEpoch 132/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - binary_accuracy: 0.5024 - loss: 0.7225 - lr: 1.2207e-05 - val_binary_accuracy: 0.4990 - val_loss: 0.7228 - learning_rate: 1.2207e-05\nEpoch 133/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - binary_accuracy: 0.5042 - loss: 0.7228 - lr: 1.2207e-05 - val_binary_accuracy: 0.4950 - val_loss: 0.7231 - learning_rate: 1.2207e-05\nEpoch 134/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - binary_accuracy: 0.5039 - loss: 0.7230 - lr: 1.2207e-05 - val_binary_accuracy: 0.5054 - val_loss: 0.7225 - learning_rate: 1.2207e-05\nEpoch 135/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - binary_accuracy: 0.5028 - loss: 0.7226 - lr: 1.2207e-05 - val_binary_accuracy: 0.5090 - val_loss: 0.7220 - learning_rate: 1.2207e-05\nEpoch 136/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - binary_accuracy: 0.5031 - loss: 0.7223 - lr: 1.2207e-05 - val_binary_accuracy: 0.4979 - val_loss: 0.7232 - learning_rate: 1.2207e-05\nEpoch 137/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - binary_accuracy: 0.5052 - loss: 0.7155 - lr: 6.1035e-06 - val_binary_accuracy: 0.4923 - val_loss: 0.7096 - learning_rate: 6.1035e-06\nEpoch 138/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 0.5016 - loss: 0.7094 - lr: 6.1035e-06 - val_binary_accuracy: 0.4896 - val_loss: 0.7082 - learning_rate: 6.1035e-06\nEpoch 139/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - binary_accuracy: 0.5021 - loss: 0.7081 - lr: 6.1035e-06 - val_binary_accuracy: 0.5025 - val_loss: 0.7085 - learning_rate: 6.1035e-06\nEpoch 140/200\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - binary_accuracy: 0.5023 - loss: 0.7078 - lr: 6.1035e-06 - val_binary_accuracy: 0.5081 - val_loss: 0.7070 - learning_rate: 6.1035e-06\nEpoch 141/200\n\u001b[1m 9/22\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.5016 - loss: 0.7077 - lr: 6.1035e-06","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-70-54dab6f03472>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 1. Create new model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model, history, params = setup_and_train(X, y, \n\u001b[0m\u001b[1;32m      3\u001b[0m                     \u001b[0mresume_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mdense_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'best_dense_only_model.keras'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-69-69d24d140d86>\u001b[0m in \u001b[0;36msetup_and_train\u001b[0;34m(X, y, resume_training, dense_only, model_path, gru_units, dense_units, dropout_rate, initial_lr, early_stopping_patience, reduce_lr_patience, reduce_lr_factor, epochs, batch_size, l1_l2_reg)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m     history = model.fit(\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":70},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot training history\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(12, 4))\n\nplt.subplot(1, 2, 1)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['binary_accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_binary_accuracy'], label='Validation Accuracy')\nplt.title('Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}