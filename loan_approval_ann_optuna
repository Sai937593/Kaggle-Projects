{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84894,"databundleVersionId":9709193,"sourceType":"competition"},{"sourceId":9706567,"sourceType":"datasetVersion","datasetId":5936521}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-24T18:56:39.020330Z","iopub.execute_input":"2024-10-24T18:56:39.020911Z","iopub.status.idle":"2024-10-24T18:56:39.034870Z","shell.execute_reply.started":"2024-10-24T18:56:39.020816Z","shell.execute_reply":"2024-10-24T18:56:39.033362Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/study-dir/loan_status_study_xgb.db\n/kaggle/input/playground-series-s4e10/sample_submission.csv\n/kaggle/input/playground-series-s4e10/train.csv\n/kaggle/input/playground-series-s4e10/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\nprint(f'reading the csv files into pandas dataframes.')\ntrain_df = pd.read_csv('/kaggle/input/playground-series-s4e10/train.csv')\ntest_df = pd.read_csv('/kaggle/input/playground-series-s4e10/test.csv')\nsub_df = pd.read_csv('/kaggle/input/playground-series-s4e10/sample_submission.csv')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:56:39.037017Z","iopub.execute_input":"2024-10-24T18:56:39.037470Z","iopub.status.idle":"2024-10-24T18:56:39.339161Z","shell.execute_reply.started":"2024-10-24T18:56:39.037427Z","shell.execute_reply":"2024-10-24T18:56:39.337659Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"reading the csv files into pandas dataframes.\n","output_type":"stream"}]},{"cell_type":"code","source":"# train_df.info()","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:56:39.341007Z","iopub.execute_input":"2024-10-24T18:56:39.341383Z","iopub.status.idle":"2024-10-24T18:56:39.346931Z","shell.execute_reply.started":"2024-10-24T18:56:39.341343Z","shell.execute_reply":"2024-10-24T18:56:39.345511Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# test_df.info()","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:56:39.348413Z","iopub.execute_input":"2024-10-24T18:56:39.348914Z","iopub.status.idle":"2024-10-24T18:56:39.358453Z","shell.execute_reply.started":"2024-10-24T18:56:39.348823Z","shell.execute_reply":"2024-10-24T18:56:39.357112Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# train_df.isnull().any(), test_df.isnull().any()","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:56:39.362554Z","iopub.execute_input":"2024-10-24T18:56:39.363121Z","iopub.status.idle":"2024-10-24T18:56:39.372124Z","shell.execute_reply.started":"2024-10-24T18:56:39.363065Z","shell.execute_reply":"2024-10-24T18:56:39.370663Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"cat_cols = train_df.select_dtypes('object').columns\nnum_cols = []\nfor col in train_df.select_dtypes(exclude='object').columns:\n    if col not in ('id', 'loan_status'):\n        num_cols.append(col)\n# num_cols, cat_cols","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:56:39.374706Z","iopub.execute_input":"2024-10-24T18:56:39.375988Z","iopub.status.idle":"2024-10-24T18:56:39.391665Z","shell.execute_reply.started":"2024-10-24T18:56:39.375940Z","shell.execute_reply":"2024-10-24T18:56:39.390340Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# train_df['loan_status'].value_counts(normalize=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:56:39.393973Z","iopub.execute_input":"2024-10-24T18:56:39.394392Z","iopub.status.idle":"2024-10-24T18:56:39.400111Z","shell.execute_reply.started":"2024-10-24T18:56:39.394348Z","shell.execute_reply":"2024-10-24T18:56:39.398662Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef box_plots_num_cols(df, columns):\n    df = df.copy()\n    base_width = 10\n    base_height = 5\n    rows = len(columns) \n    cols = 1\n    fig_width = cols * base_width\n    fig_height = rows * base_height\n    fig, axes = plt.subplots(rows, cols, figsize=(fig_width, fig_height))\n    axes = axes.flatten() if rows > 1 else [axes]\n    for i, col in enumerate(columns):\n        axes[i].boxplot(df[col])  \n        axes[i].set_title(col)\n    for j in range(i+1, len(axes)):\n        axes[j].axis('off')\n    plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:56:39.401734Z","iopub.execute_input":"2024-10-24T18:56:39.402165Z","iopub.status.idle":"2024-10-24T18:56:39.414514Z","shell.execute_reply.started":"2024-10-24T18:56:39.402124Z","shell.execute_reply":"2024-10-24T18:56:39.413367Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# box_plots_num_cols(train_df, num_cols)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:56:39.416239Z","iopub.execute_input":"2024-10-24T18:56:39.416824Z","iopub.status.idle":"2024-10-24T18:56:39.429024Z","shell.execute_reply.started":"2024-10-24T18:56:39.416770Z","shell.execute_reply":"2024-10-24T18:56:39.427539Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from scipy import stats\nimport numpy as np\n\ndef remove_outliers(df:pd.DataFrame(), cols, beta):\n    df = df.copy()\n    for col in cols:\n#         print(f'removing {col} outliers:\\n')\n        data = df[col]\n        iqr = stats.iqr(data)\n        q1 = np.percentile(data, 25)\n        q3 = np.percentile(data, 75)\n        outlier_low = q1 - beta * iqr\n        outlier_high = q1 + beta * iqr\n#         print(f'outlier_low:{outlier_low}, outlier_high: {outlier_high}')\n        df = df[(data >= outlier_low) & (data <= outlier_high)]\n    return df\n","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:56:39.430504Z","iopub.execute_input":"2024-10-24T18:56:39.430912Z","iopub.status.idle":"2024-10-24T18:56:40.103392Z","shell.execute_reply.started":"2024-10-24T18:56:39.430865Z","shell.execute_reply":"2024-10-24T18:56:40.102014Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print(f'removing outliers before oversampling')\ndf_clean = remove_outliers(train_df, num_cols, 1.5)\n# box_plots_num_cols(df_clean, num_cols)\ndf_clean.shape, train_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:56:40.104857Z","iopub.execute_input":"2024-10-24T18:56:40.105372Z","iopub.status.idle":"2024-10-24T18:56:40.199888Z","shell.execute_reply.started":"2024-10-24T18:56:40.105328Z","shell.execute_reply":"2024-10-24T18:56:40.198655Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"removing outliers before oversampling\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"((24802, 13), (58645, 13))"},"metadata":{}}]},{"cell_type":"code","source":"def hist_plot_cat_cols(df:pd.DataFrame(), cat_cols=cat_cols):\n    df = df.copy()\n    fig, axes_cat = plt.subplots(1, len(cat_cols), figsize=(20, 10))\n    for i, col in enumerate(cat_cols):\n        axes_cat[i].hist(df[col])\n        axes_cat[i].set_title(col)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:56:40.201706Z","iopub.execute_input":"2024-10-24T18:56:40.202210Z","iopub.status.idle":"2024-10-24T18:56:40.211509Z","shell.execute_reply.started":"2024-10-24T18:56:40.202155Z","shell.execute_reply":"2024-10-24T18:56:40.210258Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# hist_plot_cat_cols(train_df)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:56:40.213122Z","iopub.execute_input":"2024-10-24T18:56:40.213699Z","iopub.status.idle":"2024-10-24T18:56:40.232915Z","shell.execute_reply.started":"2024-10-24T18:56:40.213643Z","shell.execute_reply":"2024-10-24T18:56:40.231384Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# hist_plot_cat_cols(df_clean)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:56:40.239119Z","iopub.execute_input":"2024-10-24T18:56:40.239820Z","iopub.status.idle":"2024-10-24T18:56:40.246496Z","shell.execute_reply.started":"2024-10-24T18:56:40.239767Z","shell.execute_reply":"2024-10-24T18:56:40.245210Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n\nprint('encoding the categorical features')\ndf_clean = df_clean.drop(columns=['id'])\n\nord_enc = OrdinalEncoder()\none_hot_enc = OneHotEncoder(sparse_output=False)\n\nordinal_cols = ['loan_grade']\none_hot_cols = [col for col in cat_cols if col != 'loan_grade']\nremaining_cols = [col for col in df_clean.columns if col not in cat_cols]\n\nencoder = ColumnTransformer(\n            transformers=[\n                ('ordinal_encoder', ord_enc, ordinal_cols),\n                ('one_hot_encoder', one_hot_enc, one_hot_cols),\n                ('passthrough', 'passthrough', remaining_cols )\n            ]\n)\n\nencoded_data = encoder.fit_transform(df_clean)\none_hot_enc.fit(df_clean[one_hot_cols])\none_hot_encoded_cols = one_hot_enc.get_feature_names_out(one_hot_cols)\nall_cols = ordinal_cols + list(one_hot_encoded_cols) + remaining_cols\ndf_encoded = pd.DataFrame(encoded_data, columns=all_cols)\ndf_encoded.info()","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:56:40.248206Z","iopub.execute_input":"2024-10-24T18:56:40.248607Z","iopub.status.idle":"2024-10-24T18:56:40.452124Z","shell.execute_reply.started":"2024-10-24T18:56:40.248564Z","shell.execute_reply":"2024-10-24T18:56:40.450728Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"encoding the categorical features\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 24802 entries, 0 to 24801\nData columns (total 21 columns):\n #   Column                          Non-Null Count  Dtype  \n---  ------                          --------------  -----  \n 0   loan_grade                      24802 non-null  float64\n 1   person_home_ownership_MORTGAGE  24802 non-null  float64\n 2   person_home_ownership_OTHER     24802 non-null  float64\n 3   person_home_ownership_OWN       24802 non-null  float64\n 4   person_home_ownership_RENT      24802 non-null  float64\n 5   loan_intent_DEBTCONSOLIDATION   24802 non-null  float64\n 6   loan_intent_EDUCATION           24802 non-null  float64\n 7   loan_intent_HOMEIMPROVEMENT     24802 non-null  float64\n 8   loan_intent_MEDICAL             24802 non-null  float64\n 9   loan_intent_PERSONAL            24802 non-null  float64\n 10  loan_intent_VENTURE             24802 non-null  float64\n 11  cb_person_default_on_file_N     24802 non-null  float64\n 12  cb_person_default_on_file_Y     24802 non-null  float64\n 13  person_age                      24802 non-null  float64\n 14  person_income                   24802 non-null  float64\n 15  person_emp_length               24802 non-null  float64\n 16  loan_amnt                       24802 non-null  float64\n 17  loan_int_rate                   24802 non-null  float64\n 18  loan_percent_income             24802 non-null  float64\n 19  cb_person_cred_hist_length      24802 non-null  float64\n 20  loan_status                     24802 non-null  float64\ndtypes: float64(21)\nmemory usage: 4.0 MB\n","output_type":"stream"}]},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE, SVMSMOTE\n\nprint(f'oversampling using SVMSMOTE')\ndf_enc_copy = df_encoded.copy()\n\nsmote = SMOTE(random_state=32,  k_neighbors=10)\nsvm_smote = SVMSMOTE(random_state=32, k_neighbors=10,m_neighbors=10)\n\nX = df_enc_copy.drop(columns=['loan_status'])\ny = df_enc_copy.loc[:, 'loan_status']\n\nX_smote, y_smote = smote.fit_resample(X, y)\nX_svm_smote, y_svm_smote = svm_smote.fit_resample(X, y)\nX_smote.shape, y_smote.shape, X_svm_smote.shape, y_svm_smote.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:56:40.453722Z","iopub.execute_input":"2024-10-24T18:56:40.454236Z","iopub.status.idle":"2024-10-24T18:56:45.845039Z","shell.execute_reply.started":"2024-10-24T18:56:40.454181Z","shell.execute_reply":"2024-10-24T18:56:45.843711Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"oversampling using SVMSMOTE\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"((46192, 20), (46192,), (46192, 20), (46192,))"},"metadata":{}}]},{"cell_type":"code","source":"smote_df = X_smote\nsmote_df['loan_status'] = y_smote\n\nsvm_smote_df = X_svm_smote\nsvm_smote_df['loan_status'] = y_svm_smote\n","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:56:45.846905Z","iopub.execute_input":"2024-10-24T18:56:45.847599Z","iopub.status.idle":"2024-10-24T18:56:45.857762Z","shell.execute_reply.started":"2024-10-24T18:56:45.847540Z","shell.execute_reply":"2024-10-24T18:56:45.856467Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# c = [col for col in smote_df.columns if col not in one_hot_encoded_cols]\n# box_plots_num_cols(smote_df, c)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:56:45.859361Z","iopub.execute_input":"2024-10-24T18:56:45.859859Z","iopub.status.idle":"2024-10-24T18:56:45.870351Z","shell.execute_reply.started":"2024-10-24T18:56:45.859796Z","shell.execute_reply":"2024-10-24T18:56:45.869134Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# c2 = [col for col in svm_smote_df.columns if col not in one_hot_encoded_cols]\n# box_plots_num_cols(svm_smote_df, c2)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:56:45.871795Z","iopub.execute_input":"2024-10-24T18:56:45.872233Z","iopub.status.idle":"2024-10-24T18:56:45.887620Z","shell.execute_reply.started":"2024-10-24T18:56:45.872193Z","shell.execute_reply":"2024-10-24T18:56:45.886267Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# smote_corr = smote_df.corr()\n# svm_smote_corr = svm_smote_df.corr()","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:56:45.889369Z","iopub.execute_input":"2024-10-24T18:56:45.889860Z","iopub.status.idle":"2024-10-24T18:56:45.901309Z","shell.execute_reply.started":"2024-10-24T18:56:45.889796Z","shell.execute_reply":"2024-10-24T18:56:45.900086Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n\ndef heatmap_corr(corr):\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n    plt.title('Correlation Heatmap')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:56:45.902936Z","iopub.execute_input":"2024-10-24T18:56:45.903344Z","iopub.status.idle":"2024-10-24T18:56:46.313944Z","shell.execute_reply.started":"2024-10-24T18:56:45.903304Z","shell.execute_reply":"2024-10-24T18:56:46.312825Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# heatmap_corr(smote_corr)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:56:46.315291Z","iopub.execute_input":"2024-10-24T18:56:46.315873Z","iopub.status.idle":"2024-10-24T18:56:46.321671Z","shell.execute_reply.started":"2024-10-24T18:56:46.315807Z","shell.execute_reply":"2024-10-24T18:56:46.320184Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# heatmap_corr(svm_smote_corr)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:56:46.323270Z","iopub.execute_input":"2024-10-24T18:56:46.323774Z","iopub.status.idle":"2024-10-24T18:56:46.336314Z","shell.execute_reply.started":"2024-10-24T18:56:46.323717Z","shell.execute_reply":"2024-10-24T18:56:46.335136Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# high_smote_corr = smote_corr[(abs(smote_corr) > 0.7) & (abs(smote_corr) != 1.0)]\n# heatmap_corr(high_smote_corr)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:56:46.337884Z","iopub.execute_input":"2024-10-24T18:56:46.338372Z","iopub.status.idle":"2024-10-24T18:56:46.349097Z","shell.execute_reply.started":"2024-10-24T18:56:46.338318Z","shell.execute_reply":"2024-10-24T18:56:46.347448Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# high_svm_smote_corr = svm_smote_corr[(abs(svm_smote_corr) > 0.7) & (abs(svm_smote_corr) != 1.0)]\n# heatmap_corr(high_svm_smote_corr)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:56:46.350609Z","iopub.execute_input":"2024-10-24T18:56:46.351019Z","iopub.status.idle":"2024-10-24T18:56:46.362289Z","shell.execute_reply.started":"2024-10-24T18:56:46.350977Z","shell.execute_reply":"2024-10-24T18:56:46.361058Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"print('dropping the column person home ownership rent')\ndf_final = svm_smote_df.drop(columns=[ 'person_home_ownership_RENT'])\ndf_final.info()","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:56:46.364150Z","iopub.execute_input":"2024-10-24T18:56:46.364687Z","iopub.status.idle":"2024-10-24T18:56:46.393677Z","shell.execute_reply.started":"2024-10-24T18:56:46.364631Z","shell.execute_reply":"2024-10-24T18:56:46.392016Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"dropping the column person home ownership rent\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 46192 entries, 0 to 46191\nData columns (total 20 columns):\n #   Column                          Non-Null Count  Dtype  \n---  ------                          --------------  -----  \n 0   loan_grade                      46192 non-null  float64\n 1   person_home_ownership_MORTGAGE  46192 non-null  float64\n 2   person_home_ownership_OTHER     46192 non-null  float64\n 3   person_home_ownership_OWN       46192 non-null  float64\n 4   loan_intent_DEBTCONSOLIDATION   46192 non-null  float64\n 5   loan_intent_EDUCATION           46192 non-null  float64\n 6   loan_intent_HOMEIMPROVEMENT     46192 non-null  float64\n 7   loan_intent_MEDICAL             46192 non-null  float64\n 8   loan_intent_PERSONAL            46192 non-null  float64\n 9   loan_intent_VENTURE             46192 non-null  float64\n 10  cb_person_default_on_file_N     46192 non-null  float64\n 11  cb_person_default_on_file_Y     46192 non-null  float64\n 12  person_age                      46192 non-null  float64\n 13  person_income                   46192 non-null  float64\n 14  person_emp_length               46192 non-null  float64\n 15  loan_amnt                       46192 non-null  float64\n 16  loan_int_rate                   46192 non-null  float64\n 17  loan_percent_income             46192 non-null  float64\n 18  cb_person_cred_hist_length      46192 non-null  float64\n 19  loan_status                     46192 non-null  float64\ndtypes: float64(20)\nmemory usage: 7.0 MB\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\n\nprint('splitting the dataset into train and test')\nX = df_final.drop(columns=['loan_status'])\ny = df_final.loc[:, 'loan_status']\n\nsss = StratifiedShuffleSplit(n_splits=1, random_state=32, test_size=0.3)\nfor tr, te in sss.split(X, y):\n    X_train, y_train = X.iloc[tr], y.iloc[tr]\n    X_test, y_test = X.iloc[te], y.iloc[te]\nX.shape, y.shape, X_train.shape, y_train.shape, X_test.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:56:46.395348Z","iopub.execute_input":"2024-10-24T18:56:46.396419Z","iopub.status.idle":"2024-10-24T18:56:46.458945Z","shell.execute_reply.started":"2024-10-24T18:56:46.396364Z","shell.execute_reply":"2024-10-24T18:56:46.456762Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"splitting the dataset into train and test\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"((46192, 19), (46192,), (32334, 19), (32334,), (13858, 19), (13858,))"},"metadata":{}}]},{"cell_type":"code","source":"import tensorflow as tf\nimport keras \nfrom keras import activations, layers, initializers, regularizers, optimizers, losses, metrics\n\nclass ann_layer_gen:\n    def __init__(self, input_shape, batch_norm:bool=False, drop_out:bool=False, regularize:bool=False,  initiliazers:bool=False,drop_out_rate:float=0.0) -> None:\n        self.input_shape = input_shape\n        self.batch_norm = batch_norm\n        self.drop_out = drop_out\n        self.regularize = regularize\n        self.initiliazers = initiliazers\n        self.drop_out_rate = drop_out_rate\n        self.model = keras.Sequential()\n        self.model.add(keras.Input(shape=(input_shape, )))\n    \n    def __call__(self,  out_act_fun:activations, out_unit:int, units:int=100, n_hidden_layers:int=5,  hidden_act_fun:activations=activations.relu) -> keras.Sequential :\n        for n_layer in range(1, n_hidden_layers+1):\n            layer_params = {'units':units, 'activation':hidden_act_fun}\n            \n            if self.regularize:\n                layer_params['kernel_regularizer'] = regularizers.L1()\n            if self.initiliazers:\n                layer_params['kernel_initiliazer'] = initializers.glorot_normal\n            \n            self.model.add(layers.Dense(**layer_params))\n\n            if self.drop_out:\n                self.model.add(layers.Dropout(rate=self.drop_out_rate))\n\n            if self.batch_norm:\n                self.model.add(layers.BatchNormalization())\n            \n            units = round(units / 2)\n        self.model.add(layers.Dense(out_unit, activation=out_act_fun))\n        return self.model\n    \n    def compile(model, loss:losses.Loss, metrics:list=['accuracy'], optimizer:optimizers.Optimizer=optimizers.Adam, valid_split:float=0.2, learning_rate:float=0.01 ) -> keras.Sequential:\n        try:\n            model.compile(optimizer=optimizer(learning_rate=learning_rate), loss=loss, metrics=metrics)\n        except Exception as e:\n            print('Could not compile the model with given params.')\n        return model","metadata":{"execution":{"iopub.status.busy":"2024-10-24T20:03:38.041495Z","iopub.execute_input":"2024-10-24T20:03:38.042682Z","iopub.status.idle":"2024-10-24T20:03:38.055341Z","shell.execute_reply.started":"2024-10-24T20:03:38.042626Z","shell.execute_reply":"2024-10-24T20:03:38.054108Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"import optuna\nfrom  ann_layer_generator import  ann_layer_gen\nfrom keras import optimizers, activations, losses\n\ndef objective(trial:optuna.Trial):\n\n    epochs = trial.suggest_int('epochs', 10, 100, step=10)\n    units = trial.suggest_int('units', 100, 500, step=50)\n    n_hidden_layers = trial.suggest_int('n_hidden_layers', 3, 20, step=2)\n    batch_norm = trial.suggest_categorical('batch_norm', [True, False])\n    drop_out = trial.suggest_categorical('drop_out', [True, False])\n    regularize = trial.suggest_categorical('regularize', [True, False])\n    initiliazers = trial.suggest_categorical('initiliazers', [True, False])\n    drop_out_rate = trial.suggest_float('drop_out_rate', 0, 1)\n    learning_rate = trial.suggest_float('learning_rate', 0, 1, log=True)\n    optimizers_list = [optimizers.Adam(learning_rate), optimizers.RMSprop(learning_rate), optimizers.SGD(learning_rate), optimizers.Nadam(learning_rate)]\n    optimizer = trial.suggest_categorical('optimizer', optimizers_list)\n\n    init_params = {\n        'batch_norm':batch_norm,\n        'drop_out':drop_out,\n        'drop_out_rate':drop_out_rate,\n        'regularize':regularize,\n        'initiliazers':initiliazers\n    }\n    ann_layer_generator = ann_layer_gen(input_shape=X_train.shape[1], **init_params )\n    ann_model = ann_layer_generator(out_act_fun=activations.sigmoid, out_unit=1, units=units, n_hidden_layers=n_hidden_layers)\n    compiled_model = ann_layer_generator.compile(model=ann_model,loss=losses.binary_crossentropy, metrics=['accuracy'] )\n\n    compiled_model.fit(x=X_train, y=y_train, batch_size=32, epochs=epochs, validation_split=0.1,shuffle=True)\n    final_model = compiled_model\n    test, acc = compiled_model.evaluate(X_test, y_test)\n    return acc\n\n\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nloan_approval_ann_study = optuna.create_study(\n    storage='sqlite:///loan_approval_ann_study.db',\n    study_name='loan_approval_ann_study',\n    direction='maximize',\n    sampler=optuna.samplers.TPESampler\n)\n\nloan_approval_ann_study.optimize(objective, n_trials=10, show_progress_bar=True, n_jobs=-1)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n\n\nprint('encoding the final test data set')\nord_enc_test = OrdinalEncoder()\none_hot_enc_test = OneHotEncoder(sparse_output=False)\n\ntest_cat_cols = test_df.select_dtypes('object').columns\nordinal_cols = ['loan_grade']\none_hot_cols = [col for col in test_cat_cols if col != 'loan_grade']\nremaining_cols = [col for col in test_df.columns if col not in list(test_cat_cols)]\n\nencoder_test = ColumnTransformer(\n            transformers=[\n                ('ordinal_encoder', ord_enc_test, ordinal_cols),\n                ('one_hot_encoder', one_hot_enc_test, one_hot_cols),\n                ('passthrough', 'passthrough', remaining_cols )\n            ]\n)\n\nencoded_data = encoder_test.fit_transform(test_df)\none_hot_enc_test.fit(test_df[one_hot_cols])\none_hot_encoded_cols = one_hot_enc_test.get_feature_names_out(one_hot_cols)\nall_cols = ordinal_cols + list(one_hot_encoded_cols) + remaining_cols\ntest_df_encoded = pd.DataFrame(encoded_data, columns=all_cols)\ntest_df_encoded.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}